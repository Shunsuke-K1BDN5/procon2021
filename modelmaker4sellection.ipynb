{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "ジュピターで画像だけを先にロードして学習だけ書き換えることができるかのテスト"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "from os.path import join\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "## 変数群　この辺変えて\r\n",
    "size_batch = 1\r\n",
    "\r\n",
    "img_w = 16\r\n",
    "img_h = 16\r\n",
    "\r\n",
    "# 学習データの学習回数\r\n",
    "n_epoch = 20000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#学習用の画像のロード\r\n",
    "\r\n",
    "#画像を取得 return 画像のテンソル, 画像のラベル番号\r\n",
    "def get_img(path):\r\n",
    "    img = Image.open(path)\r\n",
    "    img = np.array(img, dtype=np.float32)\r\n",
    "    return img\r\n",
    "\r\n",
    "#バッチ作成\r\n",
    "def make_batch(list_path_img):\r\n",
    "    x_batch = []\r\n",
    "    t_batch = []\r\n",
    "    for path_img in list_path_img:\r\n",
    "        img = get_img(path_img)\r\n",
    "        img = np.array(img, dtype=np.float32)\r\n",
    "        img = img.transpose(2, 0, 1)\r\n",
    "        x_batch.append(img)\r\n",
    "        a = str(path_img).split('/')[-2]\r\n",
    "        a = int(a.split(\"_\")[-1])\r\n",
    "        t_batch.append(a)\r\n",
    "        #print(a)\r\n",
    "    return torch.tensor(x_batch), torch.tensor(t_batch)\r\n",
    "\r\n",
    "\r\n",
    "train_list = []\r\n",
    "x_batch = [[] for i in range(n_epoch)]\r\n",
    "t_batch = [[] for i in range(n_epoch)]\r\n",
    "\r\n",
    "for batch_number in range(n_epoch):\r\n",
    "    for k in range(img_h):\r\n",
    "        for m in range(img_w):\r\n",
    "            train_list.append(f\"C:/procon_data/data/16x16_v1/({k}, {m})_{k*img_w + m}/{batch_number}.jpg\")\r\n",
    "        x_batch[batch_number], t_batch[batch_number] = make_batch(train_list)\r\n",
    "        train_list.clear()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'get_img' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-82376c63e46b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_w\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mtrain_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"C:/procon_data/data/16x16_v1/({k}, {m})_{k*img_w + m}/{batch_number}.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mx_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_number\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_number\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mtrain_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-82376c63e46b>\u001b[0m in \u001b[0;36mmake_batch\u001b[1;34m(list_path_img)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mt_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpath_img\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_path_img\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_img' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "\r\n",
    "#NNモデル\r\n",
    "class MyNet2(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.fc1 = nn.Linear(16*16*3,768)# Input Layer to Intermediate modules\r\n",
    "        self.fc2 = nn.Linear(768,768) #Intermediate modules to Output Layer\r\n",
    "        self.fc3 = nn.Linear(768,1024) #Intermediate modules to Output Layer\r\n",
    "        self.fc4 = nn.Linear(1024,1024) #Intermediate modules to Output Layer\r\n",
    "        self.fc5 = nn.Linear(1024,1024) #Intermediate modules to Output Layer\r\n",
    "        self.fc6 = nn.Linear(1024,512)\r\n",
    "        self.fc7 = nn.Linear(512,512)\r\n",
    "        self.fc8 = nn.Linear(512,512)\r\n",
    "        self.fc9 = nn.Linear(512,256)\r\n",
    "        self.fca = nn.Linear(256,256)\r\n",
    "        self.fcb = nn.Linear(256,256)\r\n",
    "        self.fcc = nn.Linear(256,256)\r\n",
    "        self.bn0 = nn.BatchNorm2d(num_features=16) \r\n",
    "\r\n",
    "    def forward(self, x):#順伝播 Forward propagation\r\n",
    "        x = x.view(-1,16*16*3)\r\n",
    "        x = self.fc1(x)\r\n",
    "        x = self.fc2(x)\r\n",
    "        x = self.fc3(x)\r\n",
    "        x = self.fc4(x)\r\n",
    "        x = self.fc5(x)\r\n",
    "        x = self.fc6(x)\r\n",
    "        x = self.fc7(x)\r\n",
    "        x = self.fc8(x)\r\n",
    "        x = self.fc9(x)\r\n",
    "        x = self.fca(x)\r\n",
    "        x = self.fcb(x)\r\n",
    "        y = self.fcc(x)\r\n",
    "        #y = nn.Softmax(self.fcp(x))\r\n",
    "        return y\r\n",
    "\r\n",
    "\r\n",
    "#モデルに画像を入力し学習させる return なし\r\n",
    "\r\n",
    "mymodel = MyNet2().to(device)\r\n",
    "opt = optim.Adam(mymodel.parameters(), lr=0.001)\r\n",
    "print(torch.cuda.get_device_name())\r\n",
    "\r\n",
    "plot_x = []\r\n",
    "# ロスと精度を保存するリスト（訓練用・テスト用）\r\n",
    "list_loss_train = []\r\n",
    "list_loss_test = []\r\n",
    "list_acc_train = []\r\n",
    "list_acc_test = []\r\n",
    "\r\n",
    "def reset():\r\n",
    "    new_model = MyNet2()\r\n",
    "    return new_model\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a\n",
      "GeForce RTX 2060\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "i = 0\r\n",
    "temp_model = mymodel\r\n",
    "while i < n_epoch-1:#最後のやつは評価用\r\n",
    "    temp_max = 0\r\n",
    "    if i%1000 == 0 and i != 0:\r\n",
    "        #1000回やって正答率5%以下ならやり直し\r\n",
    "        print(\"1000time\")\r\n",
    "        if max(list_acc_train[i-1000:]) < 0.03 or max(list_acc_train[i-1000:]) < temp_max:\r\n",
    "            if i == 1000:\r\n",
    "                mymodel = reset()\r\n",
    "                mymodel.to(device)\r\n",
    "                i = 0\r\n",
    "            else:\r\n",
    "                mymodel = temp_model\r\n",
    "            print(\"reset\")\r\n",
    "            print(temp_model == mymodel)\r\n",
    "        else:\r\n",
    "            temp_max = max(list_acc_train[i-1000:])\r\n",
    "            temp_mpdel  = mymodel\r\n",
    "            print(f\"nice {max(list_acc_train[i-1000:])}\")\r\n",
    "    \r\n",
    "    sum_loss = 0.\r\n",
    "    sum_acc = 0.\r\n",
    "    opt.zero_grad()\r\n",
    "    x = x_batch[i].to(device)\r\n",
    "    t = t_batch[i].to(device)\r\n",
    "    y = mymodel(x)\r\n",
    "    loss = F.cross_entropy(y, t)\r\n",
    "\r\n",
    "    # 逆伝播\r\n",
    "    \r\n",
    "    loss.backward()\r\n",
    "\r\n",
    "    \r\n",
    "\r\n",
    "    # ロスと精度を蓄積\r\n",
    "    sum_loss += loss.item()\r\n",
    "    sum_acc += (y.max(1)[1] == t).sum().item()\r\n",
    "\r\n",
    "    # パラメータ更新\r\n",
    "    opt.step()\r\n",
    "    #scheduler.step()\r\n",
    "\r\n",
    "    mean_loss = sum_loss / len(x)\r\n",
    "    mean_acc = sum_acc / len(x)\r\n",
    "    list_loss_train.append(mean_loss)\r\n",
    "    list_acc_train.append(mean_acc)\r\n",
    "    plot_x.append(i)\r\n",
    "    print(f\"- now {i}\")\r\n",
    "    print(\"- mean loss:\", mean_loss)\r\n",
    "    print(\"- mean accuracy:\", mean_acc) \r\n",
    "    i += 1\r\n",
    "      \r\n",
    "\r\n",
    "print(\"fin v5 both steped\")\r\n",
    "print(\"haha\")\r\n",
    "print(list_acc_train)\r\n",
    "print(f\"max acc {max(list_acc_train)}\")\r\n",
    "print(f\"-mean acc {sum(list_acc_train)/len(list_acc_train)}\")\r\n",
    "plt.plot(plot_x,list_acc_train)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "- now 0\n",
      "- mean loss: 0.02172500640153885\n",
      "- mean accuracy: 0.00390625\n",
      "- now 1\n",
      "- mean loss: 0.02313360571861267\n",
      "- mean accuracy: 0.0\n",
      "- now 2\n",
      "- mean loss: 0.05432939901947975\n",
      "- mean accuracy: 0.00390625\n",
      "- now 3\n",
      "- mean loss: 0.03593531250953674\n",
      "- mean accuracy: 0.00390625\n",
      "- now 4\n",
      "- mean loss: 0.038800790905952454\n",
      "- mean accuracy: 0.00390625\n",
      "- now 5\n",
      "- mean loss: 0.04579285904765129\n",
      "- mean accuracy: 0.00390625\n",
      "- now 6\n",
      "- mean loss: 0.08561109006404877\n",
      "- mean accuracy: 0.00390625\n",
      "- now 7\n",
      "- mean loss: 0.10734203457832336\n",
      "- mean accuracy: 0.00390625\n",
      "- now 8\n",
      "- mean loss: 0.05738551542162895\n",
      "- mean accuracy: 0.00390625\n",
      "- now 9\n",
      "- mean loss: 0.2653394341468811\n",
      "- mean accuracy: 0.00390625\n",
      "- now 10\n",
      "- mean loss: 0.14502637088298798\n",
      "- mean accuracy: 0.00390625\n",
      "- now 11\n",
      "- mean loss: 0.07477810233831406\n",
      "- mean accuracy: 0.00390625\n",
      "- now 12\n",
      "- mean loss: 0.28518521785736084\n",
      "- mean accuracy: 0.00390625\n",
      "- now 13\n",
      "- mean loss: 0.09897390007972717\n",
      "- mean accuracy: 0.00390625\n",
      "- now 14\n",
      "- mean loss: 0.02874051034450531\n",
      "- mean accuracy: 0.00390625\n",
      "- now 15\n",
      "- mean loss: 0.0839463621377945\n",
      "- mean accuracy: 0.00390625\n",
      "- now 16\n",
      "- mean loss: 0.09686058014631271\n",
      "- mean accuracy: 0.00390625\n",
      "- now 17\n",
      "- mean loss: 0.0670965164899826\n",
      "- mean accuracy: 0.00390625\n",
      "- now 18\n",
      "- mean loss: 0.19675463438034058\n",
      "- mean accuracy: 0.00390625\n",
      "- now 19\n",
      "- mean loss: 0.08709713816642761\n",
      "- mean accuracy: 0.00390625\n",
      "- now 20\n",
      "- mean loss: 0.12351784855127335\n",
      "- mean accuracy: 0.00390625\n",
      "- now 21\n",
      "- mean loss: 0.02355528250336647\n",
      "- mean accuracy: 0.0\n",
      "- now 22\n",
      "- mean loss: 0.031192269176244736\n",
      "- mean accuracy: 0.0\n",
      "- now 23\n",
      "- mean loss: 0.059317246079444885\n",
      "- mean accuracy: 0.00390625\n",
      "- now 24\n",
      "- mean loss: 0.061795808374881744\n",
      "- mean accuracy: 0.00390625\n",
      "- now 25\n",
      "- mean loss: 0.047125231474637985\n",
      "- mean accuracy: 0.00390625\n",
      "- now 26\n",
      "- mean loss: 0.21895189583301544\n",
      "- mean accuracy: 0.00390625\n",
      "- now 27\n",
      "- mean loss: 0.03900782763957977\n",
      "- mean accuracy: 0.00390625\n",
      "- now 28\n",
      "- mean loss: 0.04815494641661644\n",
      "- mean accuracy: 0.00390625\n",
      "- now 29\n",
      "- mean loss: 0.04100382700562477\n",
      "- mean accuracy: 0.00390625\n",
      "- now 30\n",
      "- mean loss: 0.026657698675990105\n",
      "- mean accuracy: 0.0078125\n",
      "- now 31\n",
      "- mean loss: 0.03329373151063919\n",
      "- mean accuracy: 0.00390625\n",
      "- now 32\n",
      "- mean loss: 0.0534261129796505\n",
      "- mean accuracy: 0.00390625\n",
      "- now 33\n",
      "- mean loss: 0.046664219349622726\n",
      "- mean accuracy: 0.00390625\n",
      "- now 34\n",
      "- mean loss: 0.04485331103205681\n",
      "- mean accuracy: 0.00390625\n",
      "- now 35\n",
      "- mean loss: 0.029692798852920532\n",
      "- mean accuracy: 0.00390625\n",
      "- now 36\n",
      "- mean loss: 0.039525680243968964\n",
      "- mean accuracy: 0.0\n",
      "- now 37\n",
      "- mean loss: 0.023920942097902298\n",
      "- mean accuracy: 0.0078125\n",
      "- now 38\n",
      "- mean loss: 0.028349529951810837\n",
      "- mean accuracy: 0.00390625\n",
      "- now 39\n",
      "- mean loss: 0.025214163586497307\n",
      "- mean accuracy: 0.00390625\n",
      "- now 40\n",
      "- mean loss: 0.02414299175143242\n",
      "- mean accuracy: 0.0\n",
      "- now 41\n",
      "- mean loss: 0.03185670077800751\n",
      "- mean accuracy: 0.00390625\n",
      "- now 42\n",
      "- mean loss: 0.024373654276132584\n",
      "- mean accuracy: 0.00390625\n",
      "- now 43\n",
      "- mean loss: 0.028517460450530052\n",
      "- mean accuracy: 0.0\n",
      "- now 44\n",
      "- mean loss: 0.027639487758278847\n",
      "- mean accuracy: 0.00390625\n",
      "- now 45\n",
      "- mean loss: 0.024791423231363297\n",
      "- mean accuracy: 0.00390625\n",
      "- now 46\n",
      "- mean loss: 0.023393280804157257\n",
      "- mean accuracy: 0.00390625\n",
      "- now 47\n",
      "- mean loss: 0.022796599194407463\n",
      "- mean accuracy: 0.0078125\n",
      "- now 48\n",
      "- mean loss: 0.02248281240463257\n",
      "- mean accuracy: 0.00390625\n",
      "- now 49\n",
      "- mean loss: 0.022359631955623627\n",
      "- mean accuracy: 0.00390625\n",
      "- now 50\n",
      "- mean loss: 0.022448088973760605\n",
      "- mean accuracy: 0.01171875\n",
      "- now 51\n",
      "- mean loss: 0.02247263304889202\n",
      "- mean accuracy: 0.0078125\n",
      "- now 52\n",
      "- mean loss: 0.02238389477133751\n",
      "- mean accuracy: 0.0\n",
      "- now 53\n",
      "- mean loss: 0.02245132438838482\n",
      "- mean accuracy: 0.0\n",
      "- now 54\n",
      "- mean loss: 0.022250274196267128\n",
      "- mean accuracy: 0.0\n",
      "- now 55\n",
      "- mean loss: 0.022133946418762207\n",
      "- mean accuracy: 0.0\n",
      "- now 56\n",
      "- mean loss: 0.021970849484205246\n",
      "- mean accuracy: 0.0\n",
      "- now 57\n",
      "- mean loss: 0.02187546156346798\n",
      "- mean accuracy: 0.00390625\n",
      "- now 58\n",
      "- mean loss: 0.021893901750445366\n",
      "- mean accuracy: 0.0\n",
      "- now 59\n",
      "- mean loss: 0.02198052406311035\n",
      "- mean accuracy: 0.0\n",
      "- now 60\n",
      "- mean loss: 0.02187528647482395\n",
      "- mean accuracy: 0.0\n",
      "- now 61\n",
      "- mean loss: 0.021844353526830673\n",
      "- mean accuracy: 0.0078125\n",
      "- now 62\n",
      "- mean loss: 0.02191944047808647\n",
      "- mean accuracy: 0.0\n",
      "- now 63\n",
      "- mean loss: 0.021853933110833168\n",
      "- mean accuracy: 0.00390625\n",
      "- now 64\n",
      "- mean loss: 0.021753083914518356\n",
      "- mean accuracy: 0.0078125\n",
      "- now 65\n",
      "- mean loss: 0.021712923422455788\n",
      "- mean accuracy: 0.00390625\n",
      "- now 66\n",
      "- mean loss: 0.02181381918489933\n",
      "- mean accuracy: 0.00390625\n",
      "- now 67\n",
      "- mean loss: 0.021771851927042007\n",
      "- mean accuracy: 0.0078125\n",
      "- now 68\n",
      "- mean loss: 0.02182421088218689\n",
      "- mean accuracy: 0.0\n",
      "- now 69\n",
      "- mean loss: 0.02183256484568119\n",
      "- mean accuracy: 0.0\n",
      "- now 70\n",
      "- mean loss: 0.021769117563962936\n",
      "- mean accuracy: 0.0\n",
      "- now 71\n",
      "- mean loss: 0.02178362011909485\n",
      "- mean accuracy: 0.00390625\n",
      "- now 72\n",
      "- mean loss: 0.021707281470298767\n",
      "- mean accuracy: 0.00390625\n",
      "- now 73\n",
      "- mean loss: 0.021733423694968224\n",
      "- mean accuracy: 0.0\n",
      "- now 74\n",
      "- mean loss: 0.02178341895341873\n",
      "- mean accuracy: 0.0078125\n",
      "- now 75\n",
      "- mean loss: 0.021759364753961563\n",
      "- mean accuracy: 0.0\n",
      "- now 76\n",
      "- mean loss: 0.021760405972599983\n",
      "- mean accuracy: 0.0\n",
      "- now 77\n",
      "- mean loss: 0.02165566198527813\n",
      "- mean accuracy: 0.0\n",
      "- now 78\n",
      "- mean loss: 0.021650463342666626\n",
      "- mean accuracy: 0.0\n",
      "- now 79\n",
      "- mean loss: 0.021646985784173012\n",
      "- mean accuracy: 0.0078125\n",
      "- now 80\n",
      "- mean loss: 0.02172640711069107\n",
      "- mean accuracy: 0.0\n",
      "- now 81\n",
      "- mean loss: 0.021829575300216675\n",
      "- mean accuracy: 0.0\n",
      "- now 82\n",
      "- mean loss: 0.021786823868751526\n",
      "- mean accuracy: 0.00390625\n",
      "- now 83\n",
      "- mean loss: 0.021811289712786674\n",
      "- mean accuracy: 0.00390625\n",
      "- now 84\n",
      "- mean loss: 0.0217400211840868\n",
      "- mean accuracy: 0.0\n",
      "- now 85\n",
      "- mean loss: 0.021729527041316032\n",
      "- mean accuracy: 0.0\n",
      "- now 86\n",
      "- mean loss: 0.021721942350268364\n",
      "- mean accuracy: 0.00390625\n",
      "- now 87\n",
      "- mean loss: 0.02171516977250576\n",
      "- mean accuracy: 0.00390625\n",
      "- now 88\n",
      "- mean loss: 0.021758509799838066\n",
      "- mean accuracy: 0.00390625\n",
      "- now 89\n",
      "- mean loss: 0.02176392637193203\n",
      "- mean accuracy: 0.0\n",
      "- now 90\n",
      "- mean loss: 0.021695295348763466\n",
      "- mean accuracy: 0.0\n",
      "- now 91\n",
      "- mean loss: 0.02162581868469715\n",
      "- mean accuracy: 0.0078125\n",
      "- now 92\n",
      "- mean loss: 0.0216677188873291\n",
      "- mean accuracy: 0.00390625\n",
      "- now 93\n",
      "- mean loss: 0.02170417457818985\n",
      "- mean accuracy: 0.00390625\n",
      "- now 94\n",
      "- mean loss: 0.02171555906534195\n",
      "- mean accuracy: 0.01171875\n",
      "- now 95\n",
      "- mean loss: 0.021751418709754944\n",
      "- mean accuracy: 0.0\n",
      "- now 96\n",
      "- mean loss: 0.021705899387598038\n",
      "- mean accuracy: 0.00390625\n",
      "- now 97\n",
      "- mean loss: 0.02170621231198311\n",
      "- mean accuracy: 0.0\n",
      "- now 98\n",
      "- mean loss: 0.02170642279088497\n",
      "- mean accuracy: 0.00390625\n",
      "- now 99\n",
      "- mean loss: 0.021808987483382225\n",
      "- mean accuracy: 0.00390625\n",
      "- now 100\n",
      "- mean loss: 0.021758997812867165\n",
      "- mean accuracy: 0.0\n",
      "- now 101\n",
      "- mean loss: 0.021795617416501045\n",
      "- mean accuracy: 0.0\n",
      "- now 102\n",
      "- mean loss: 0.021724525839090347\n",
      "- mean accuracy: 0.0\n",
      "- now 103\n",
      "- mean loss: 0.021758833900094032\n",
      "- mean accuracy: 0.0\n",
      "- now 104\n",
      "- mean loss: 0.021747738122940063\n",
      "- mean accuracy: 0.00390625\n",
      "- now 105\n",
      "- mean loss: 0.021704528480768204\n",
      "- mean accuracy: 0.00390625\n",
      "- now 106\n",
      "- mean loss: 0.021728957071900368\n",
      "- mean accuracy: 0.00390625\n",
      "- now 107\n",
      "- mean loss: 0.021712983027100563\n",
      "- mean accuracy: 0.00390625\n",
      "- now 108\n",
      "- mean loss: 0.02176029421389103\n",
      "- mean accuracy: 0.0\n",
      "- now 109\n",
      "- mean loss: 0.02169550210237503\n",
      "- mean accuracy: 0.0\n",
      "- now 110\n",
      "- mean loss: 0.021747175604104996\n",
      "- mean accuracy: 0.00390625\n",
      "- now 111\n",
      "- mean loss: 0.021682539954781532\n",
      "- mean accuracy: 0.0078125\n",
      "- now 112\n",
      "- mean loss: 0.021757951006293297\n",
      "- mean accuracy: 0.00390625\n",
      "- now 113\n",
      "- mean loss: 0.021762261167168617\n",
      "- mean accuracy: 0.015625\n",
      "- now 114\n",
      "- mean loss: 0.021728765219449997\n",
      "- mean accuracy: 0.00390625\n",
      "- now 115\n",
      "- mean loss: 0.021619362756609917\n",
      "- mean accuracy: 0.0078125\n",
      "- now 116\n",
      "- mean loss: 0.021740030497312546\n",
      "- mean accuracy: 0.0078125\n",
      "- now 117\n",
      "- mean loss: 0.021684015169739723\n",
      "- mean accuracy: 0.01171875\n",
      "- now 118\n",
      "- mean loss: 0.02161921001970768\n",
      "- mean accuracy: 0.0078125\n",
      "- now 119\n",
      "- mean loss: 0.021681472659111023\n",
      "- mean accuracy: 0.0\n",
      "- now 120\n",
      "- mean loss: 0.02171611785888672\n",
      "- mean accuracy: 0.00390625\n",
      "- now 121\n",
      "- mean loss: 0.021639076992869377\n",
      "- mean accuracy: 0.00390625\n",
      "- now 122\n",
      "- mean loss: 0.021660396829247475\n",
      "- mean accuracy: 0.0078125\n",
      "- now 123\n",
      "- mean loss: 0.021715372800827026\n",
      "- mean accuracy: 0.00390625\n",
      "- now 124\n",
      "- mean loss: 0.02172805182635784\n",
      "- mean accuracy: 0.00390625\n",
      "- now 125\n",
      "- mean loss: 0.021659743040800095\n",
      "- mean accuracy: 0.00390625\n",
      "- now 126\n",
      "- mean loss: 0.021690532565116882\n",
      "- mean accuracy: 0.0078125\n",
      "- now 127\n",
      "- mean loss: 0.021693605929613113\n",
      "- mean accuracy: 0.00390625\n",
      "- now 128\n",
      "- mean loss: 0.02167414128780365\n",
      "- mean accuracy: 0.01171875\n",
      "- now 129\n",
      "- mean loss: 0.021696895360946655\n",
      "- mean accuracy: 0.00390625\n",
      "- now 130\n",
      "- mean loss: 0.021741928532719612\n",
      "- mean accuracy: 0.0\n",
      "- now 131\n",
      "- mean loss: 0.02177862450480461\n",
      "- mean accuracy: 0.0078125\n",
      "- now 132\n",
      "- mean loss: 0.021713625639677048\n",
      "- mean accuracy: 0.00390625\n",
      "- now 133\n",
      "- mean loss: 0.021692799404263496\n",
      "- mean accuracy: 0.0\n",
      "- now 134\n",
      "- mean loss: 0.02162264846265316\n",
      "- mean accuracy: 0.00390625\n",
      "- now 135\n",
      "- mean loss: 0.02170359343290329\n",
      "- mean accuracy: 0.00390625\n",
      "- now 136\n",
      "- mean loss: 0.021684175357222557\n",
      "- mean accuracy: 0.00390625\n",
      "- now 137\n",
      "- mean loss: 0.021656280383467674\n",
      "- mean accuracy: 0.00390625\n",
      "- now 138\n",
      "- mean loss: 0.02171987295150757\n",
      "- mean accuracy: 0.00390625\n",
      "- now 139\n",
      "- mean loss: 0.021656258031725883\n",
      "- mean accuracy: 0.00390625\n",
      "- now 140\n",
      "- mean loss: 0.021624566987156868\n",
      "- mean accuracy: 0.0\n",
      "- now 141\n",
      "- mean loss: 0.02166612073779106\n",
      "- mean accuracy: 0.0078125\n",
      "- now 142\n",
      "- mean loss: 0.02174231968820095\n",
      "- mean accuracy: 0.0\n",
      "- now 143\n",
      "- mean loss: 0.02174292877316475\n",
      "- mean accuracy: 0.00390625\n",
      "- now 144\n",
      "- mean loss: 0.021761711686849594\n",
      "- mean accuracy: 0.00390625\n",
      "- now 145\n",
      "- mean loss: 0.021764209493994713\n",
      "- mean accuracy: 0.0078125\n",
      "- now 146\n",
      "- mean loss: 0.021707210689783096\n",
      "- mean accuracy: 0.01171875\n",
      "- now 147\n",
      "- mean loss: 0.021719904616475105\n",
      "- mean accuracy: 0.0\n",
      "- now 148\n",
      "- mean loss: 0.021704860031604767\n",
      "- mean accuracy: 0.0078125\n",
      "- now 149\n",
      "- mean loss: 0.02169216051697731\n",
      "- mean accuracy: 0.0078125\n",
      "- now 150\n",
      "- mean loss: 0.02173926867544651\n",
      "- mean accuracy: 0.0\n",
      "- now 151\n",
      "- mean loss: 0.02175282873213291\n",
      "- mean accuracy: 0.0078125\n",
      "- now 152\n",
      "- mean loss: 0.02180619165301323\n",
      "- mean accuracy: 0.00390625\n",
      "- now 153\n",
      "- mean loss: 0.021656692028045654\n",
      "- mean accuracy: 0.00390625\n",
      "- now 154\n",
      "- mean loss: 0.021674025803804398\n",
      "- mean accuracy: 0.0078125\n",
      "- now 155\n",
      "- mean loss: 0.02174520492553711\n",
      "- mean accuracy: 0.0\n",
      "- now 156\n",
      "- mean loss: 0.02167895808815956\n",
      "- mean accuracy: 0.0\n",
      "- now 157\n",
      "- mean loss: 0.02169243060052395\n",
      "- mean accuracy: 0.0078125\n",
      "- now 158\n",
      "- mean loss: 0.021700305864214897\n",
      "- mean accuracy: 0.01171875\n",
      "- now 159\n",
      "- mean loss: 0.021786455065011978\n",
      "- mean accuracy: 0.0078125\n",
      "- now 160\n",
      "- mean loss: 0.02174358442425728\n",
      "- mean accuracy: 0.0\n",
      "- now 161\n",
      "- mean loss: 0.021657034754753113\n",
      "- mean accuracy: 0.00390625\n",
      "- now 162\n",
      "- mean loss: 0.021657487377524376\n",
      "- mean accuracy: 0.00390625\n",
      "- now 163\n",
      "- mean loss: 0.021672401577234268\n",
      "- mean accuracy: 0.0\n",
      "- now 164\n",
      "- mean loss: 0.021631399169564247\n",
      "- mean accuracy: 0.0078125\n",
      "- now 165\n",
      "- mean loss: 0.021663181483745575\n",
      "- mean accuracy: 0.01171875\n",
      "- now 166\n",
      "- mean loss: 0.021737558767199516\n",
      "- mean accuracy: 0.00390625\n",
      "- now 167\n",
      "- mean loss: 0.021722210571169853\n",
      "- mean accuracy: 0.01171875\n",
      "- now 168\n",
      "- mean loss: 0.021745001897215843\n",
      "- mean accuracy: 0.00390625\n",
      "- now 169\n",
      "- mean loss: 0.021758481860160828\n",
      "- mean accuracy: 0.00390625\n",
      "- now 170\n",
      "- mean loss: 0.021714918315410614\n",
      "- mean accuracy: 0.015625\n",
      "- now 171\n",
      "- mean loss: 0.0216271560639143\n",
      "- mean accuracy: 0.01171875\n",
      "- now 172\n",
      "- mean loss: 0.021666383370757103\n",
      "- mean accuracy: 0.0\n",
      "- now 173\n",
      "- mean loss: 0.021689238026738167\n",
      "- mean accuracy: 0.00390625\n",
      "- now 174\n",
      "- mean loss: 0.02167905494570732\n",
      "- mean accuracy: 0.00390625\n",
      "- now 175\n",
      "- mean loss: 0.0216240081936121\n",
      "- mean accuracy: 0.0078125\n",
      "- now 176\n",
      "- mean loss: 0.02159550040960312\n",
      "- mean accuracy: 0.0078125\n",
      "- now 177\n",
      "- mean loss: 0.02165139652788639\n",
      "- mean accuracy: 0.015625\n",
      "- now 178\n",
      "- mean loss: 0.0216651801019907\n",
      "- mean accuracy: 0.00390625\n",
      "- now 179\n",
      "- mean loss: 0.021702012047171593\n",
      "- mean accuracy: 0.01171875\n",
      "- now 180\n",
      "- mean loss: 0.021719755604863167\n",
      "- mean accuracy: 0.0\n",
      "- now 181\n",
      "- mean loss: 0.02169383130967617\n",
      "- mean accuracy: 0.0078125\n",
      "- now 182\n",
      "- mean loss: 0.021749230101704597\n",
      "- mean accuracy: 0.01171875\n",
      "- now 183\n",
      "- mean loss: 0.021648481488227844\n",
      "- mean accuracy: 0.00390625\n",
      "- now 184\n",
      "- mean loss: 0.021797658875584602\n",
      "- mean accuracy: 0.0078125\n",
      "- now 185\n",
      "- mean loss: 0.021757809445261955\n",
      "- mean accuracy: 0.00390625\n",
      "- now 186\n",
      "- mean loss: 0.02169094607234001\n",
      "- mean accuracy: 0.0078125\n",
      "- now 187\n",
      "- mean loss: 0.021724000573158264\n",
      "- mean accuracy: 0.0078125\n",
      "- now 188\n",
      "- mean loss: 0.02164895460009575\n",
      "- mean accuracy: 0.01171875\n",
      "- now 189\n",
      "- mean loss: 0.021616773679852486\n",
      "- mean accuracy: 0.0078125\n",
      "- now 190\n",
      "- mean loss: 0.02164330706000328\n",
      "- mean accuracy: 0.00390625\n",
      "- now 191\n",
      "- mean loss: 0.021583369001746178\n",
      "- mean accuracy: 0.0078125\n",
      "- now 192\n",
      "- mean loss: 0.021658843383193016\n",
      "- mean accuracy: 0.00390625\n",
      "- now 193\n",
      "- mean loss: 0.02162238210439682\n",
      "- mean accuracy: 0.015625\n",
      "- now 194\n",
      "- mean loss: 0.021629782393574715\n",
      "- mean accuracy: 0.01953125\n",
      "- now 195\n",
      "- mean loss: 0.02163076400756836\n",
      "- mean accuracy: 0.01171875\n",
      "- now 196\n",
      "- mean loss: 0.021681837737560272\n",
      "- mean accuracy: 0.00390625\n",
      "- now 197\n",
      "- mean loss: 0.02157931961119175\n",
      "- mean accuracy: 0.0234375\n",
      "- now 198\n",
      "- mean loss: 0.02166053280234337\n",
      "- mean accuracy: 0.00390625\n",
      "- now 199\n",
      "- mean loss: 0.021641233935952187\n",
      "- mean accuracy: 0.00390625\n",
      "- now 200\n",
      "- mean loss: 0.021622709929943085\n",
      "- mean accuracy: 0.01171875\n",
      "- now 201\n",
      "- mean loss: 0.021649278700351715\n",
      "- mean accuracy: 0.00390625\n",
      "- now 202\n",
      "- mean loss: 0.021650617942214012\n",
      "- mean accuracy: 0.00390625\n",
      "- now 203\n",
      "- mean loss: 0.0216368455439806\n",
      "- mean accuracy: 0.01171875\n",
      "- now 204\n",
      "- mean loss: 0.02154705300927162\n",
      "- mean accuracy: 0.01171875\n",
      "- now 205\n",
      "- mean loss: 0.021564217284321785\n",
      "- mean accuracy: 0.0\n",
      "- now 206\n",
      "- mean loss: 0.021475788205862045\n",
      "- mean accuracy: 0.00390625\n",
      "- now 207\n",
      "- mean loss: 0.02148289605975151\n",
      "- mean accuracy: 0.01171875\n",
      "- now 208\n",
      "- mean loss: 0.021476605907082558\n",
      "- mean accuracy: 0.01171875\n",
      "- now 209\n",
      "- mean loss: 0.021558726206421852\n",
      "- mean accuracy: 0.00390625\n",
      "- now 210\n",
      "- mean loss: 0.021567391231656075\n",
      "- mean accuracy: 0.0078125\n",
      "- now 211\n",
      "- mean loss: 0.021588264033198357\n",
      "- mean accuracy: 0.0078125\n",
      "- now 212\n",
      "- mean loss: 0.021617569029331207\n",
      "- mean accuracy: 0.00390625\n",
      "- now 213\n",
      "- mean loss: 0.021570149809122086\n",
      "- mean accuracy: 0.0078125\n",
      "- now 214\n",
      "- mean loss: 0.02158355340361595\n",
      "- mean accuracy: 0.00390625\n",
      "- now 215\n",
      "- mean loss: 0.02162858285009861\n",
      "- mean accuracy: 0.00390625\n",
      "- now 216\n",
      "- mean loss: 0.021616054698824883\n",
      "- mean accuracy: 0.0078125\n",
      "- now 217\n",
      "- mean loss: 0.021654866635799408\n",
      "- mean accuracy: 0.0078125\n",
      "- now 218\n",
      "- mean loss: 0.021643657237291336\n",
      "- mean accuracy: 0.0\n",
      "- now 219\n",
      "- mean loss: 0.021605011075735092\n",
      "- mean accuracy: 0.0078125\n",
      "- now 220\n",
      "- mean loss: 0.021579599007964134\n",
      "- mean accuracy: 0.0078125\n",
      "- now 221\n",
      "- mean loss: 0.021475855261087418\n",
      "- mean accuracy: 0.00390625\n",
      "- now 222\n",
      "- mean loss: 0.02142350561916828\n",
      "- mean accuracy: 0.0\n",
      "- now 223\n",
      "- mean loss: 0.021476373076438904\n",
      "- mean accuracy: 0.00390625\n",
      "- now 224\n",
      "- mean loss: 0.021468237042427063\n",
      "- mean accuracy: 0.0\n",
      "- now 225\n",
      "- mean loss: 0.0215072650462389\n",
      "- mean accuracy: 0.00390625\n",
      "- now 226\n",
      "- mean loss: 0.021497933194041252\n",
      "- mean accuracy: 0.0\n",
      "- now 227\n",
      "- mean loss: 0.021490950137376785\n",
      "- mean accuracy: 0.015625\n",
      "- now 228\n",
      "- mean loss: 0.021510588005185127\n",
      "- mean accuracy: 0.0078125\n",
      "- now 229\n",
      "- mean loss: 0.021448351442813873\n",
      "- mean accuracy: 0.01171875\n",
      "- now 230\n",
      "- mean loss: 0.02140428125858307\n",
      "- mean accuracy: 0.01171875\n",
      "- now 231\n",
      "- mean loss: 0.021344803273677826\n",
      "- mean accuracy: 0.0078125\n",
      "- now 232\n",
      "- mean loss: 0.02131602354347706\n",
      "- mean accuracy: 0.015625\n",
      "- now 233\n",
      "- mean loss: 0.021295223385095596\n",
      "- mean accuracy: 0.0078125\n",
      "- now 234\n",
      "- mean loss: 0.02131359465420246\n",
      "- mean accuracy: 0.0078125\n",
      "- now 235\n",
      "- mean loss: 0.021320777013897896\n",
      "- mean accuracy: 0.0\n",
      "- now 236\n",
      "- mean loss: 0.021282808855175972\n",
      "- mean accuracy: 0.0078125\n",
      "- now 237\n",
      "- mean loss: 0.021135656163096428\n",
      "- mean accuracy: 0.0078125\n",
      "- now 238\n",
      "- mean loss: 0.02116217650473118\n",
      "- mean accuracy: 0.0\n",
      "- now 239\n",
      "- mean loss: 0.0210963673889637\n",
      "- mean accuracy: 0.01171875\n",
      "- now 240\n",
      "- mean loss: 0.021048497408628464\n",
      "- mean accuracy: 0.0078125\n",
      "- now 241\n",
      "- mean loss: 0.021138334646821022\n",
      "- mean accuracy: 0.0078125\n",
      "- now 242\n",
      "- mean loss: 0.02102278731763363\n",
      "- mean accuracy: 0.0078125\n",
      "- now 243\n",
      "- mean loss: 0.020937548950314522\n",
      "- mean accuracy: 0.0078125\n",
      "- now 244\n",
      "- mean loss: 0.02094765566289425\n",
      "- mean accuracy: 0.01171875\n",
      "- now 245\n",
      "- mean loss: 0.020783111453056335\n",
      "- mean accuracy: 0.015625\n",
      "- now 246\n",
      "- mean loss: 0.020800389349460602\n",
      "- mean accuracy: 0.01171875\n",
      "- now 247\n",
      "- mean loss: 0.020878080278635025\n",
      "- mean accuracy: 0.015625\n",
      "- now 248\n",
      "- mean loss: 0.020817432552576065\n",
      "- mean accuracy: 0.015625\n",
      "- now 249\n",
      "- mean loss: 0.020935988053679466\n",
      "- mean accuracy: 0.015625\n",
      "- now 250\n",
      "- mean loss: 0.020791081711649895\n",
      "- mean accuracy: 0.01171875\n",
      "- now 251\n",
      "- mean loss: 0.020726457238197327\n",
      "- mean accuracy: 0.015625\n",
      "- now 252\n",
      "- mean loss: 0.02063128724694252\n",
      "- mean accuracy: 0.01953125\n",
      "- now 253\n",
      "- mean loss: 0.02059076726436615\n",
      "- mean accuracy: 0.00390625\n",
      "- now 254\n",
      "- mean loss: 0.020599907264113426\n",
      "- mean accuracy: 0.0078125\n",
      "- now 255\n",
      "- mean loss: 0.020299721509218216\n",
      "- mean accuracy: 0.01953125\n",
      "- now 256\n",
      "- mean loss: 0.020254988223314285\n",
      "- mean accuracy: 0.0234375\n",
      "- now 257\n",
      "- mean loss: 0.02031804621219635\n",
      "- mean accuracy: 0.0078125\n",
      "- now 258\n",
      "- mean loss: 0.020142855122685432\n",
      "- mean accuracy: 0.015625\n",
      "- now 259\n",
      "- mean loss: 0.01996401883661747\n",
      "- mean accuracy: 0.01953125\n",
      "- now 260\n",
      "- mean loss: 0.019851628690958023\n",
      "- mean accuracy: 0.015625\n",
      "- now 261\n",
      "- mean loss: 0.019889285787940025\n",
      "- mean accuracy: 0.01171875\n",
      "- now 262\n",
      "- mean loss: 0.019645504653453827\n",
      "- mean accuracy: 0.01953125\n",
      "- now 263\n",
      "- mean loss: 0.019650744274258614\n",
      "- mean accuracy: 0.01171875\n",
      "- now 264\n",
      "- mean loss: 0.01952447183430195\n",
      "- mean accuracy: 0.00390625\n",
      "- now 265\n",
      "- mean loss: 0.019503455609083176\n",
      "- mean accuracy: 0.015625\n",
      "- now 266\n",
      "- mean loss: 0.019298676401376724\n",
      "- mean accuracy: 0.015625\n",
      "- now 267\n",
      "- mean loss: 0.01916375197470188\n",
      "- mean accuracy: 0.02734375\n",
      "- now 268\n",
      "- mean loss: 0.01889348216354847\n",
      "- mean accuracy: 0.0078125\n",
      "- now 269\n",
      "- mean loss: 0.018741782754659653\n",
      "- mean accuracy: 0.01171875\n",
      "- now 270\n",
      "- mean loss: 0.018676819279789925\n",
      "- mean accuracy: 0.0078125\n",
      "- now 271\n",
      "- mean loss: 0.018550852313637733\n",
      "- mean accuracy: 0.02734375\n",
      "- now 272\n",
      "- mean loss: 0.018587857484817505\n",
      "- mean accuracy: 0.01953125\n",
      "- now 273\n",
      "- mean loss: 0.01861245557665825\n",
      "- mean accuracy: 0.015625\n",
      "- now 274\n",
      "- mean loss: 0.018773099407553673\n",
      "- mean accuracy: 0.0078125\n",
      "- now 275\n",
      "- mean loss: 0.018495483323931694\n",
      "- mean accuracy: 0.01171875\n",
      "- now 276\n",
      "- mean loss: 0.0183025524020195\n",
      "- mean accuracy: 0.03125\n",
      "- now 277\n",
      "- mean loss: 0.018182016909122467\n",
      "- mean accuracy: 0.03125\n",
      "- now 278\n",
      "- mean loss: 0.017899541184306145\n",
      "- mean accuracy: 0.03125\n",
      "- now 279\n",
      "- mean loss: 0.01801719143986702\n",
      "- mean accuracy: 0.0234375\n",
      "- now 280\n",
      "- mean loss: 0.018036412075161934\n",
      "- mean accuracy: 0.02734375\n",
      "- now 281\n",
      "- mean loss: 0.018132178112864494\n",
      "- mean accuracy: 0.01953125\n",
      "- now 282\n",
      "- mean loss: 0.018141640350222588\n",
      "- mean accuracy: 0.02734375\n",
      "- now 283\n",
      "- mean loss: 0.018256276845932007\n",
      "- mean accuracy: 0.01953125\n",
      "- now 284\n",
      "- mean loss: 0.01791088655591011\n",
      "- mean accuracy: 0.0234375\n",
      "- now 285\n",
      "- mean loss: 0.017806818708777428\n",
      "- mean accuracy: 0.02734375\n",
      "- now 286\n",
      "- mean loss: 0.017750617116689682\n",
      "- mean accuracy: 0.03125\n",
      "- now 287\n",
      "- mean loss: 0.017474792897701263\n",
      "- mean accuracy: 0.02734375\n",
      "- now 288\n",
      "- mean loss: 0.01773947663605213\n",
      "- mean accuracy: 0.02734375\n",
      "- now 289\n",
      "- mean loss: 0.017782658338546753\n",
      "- mean accuracy: 0.01953125\n",
      "- now 290\n",
      "- mean loss: 0.017596961930394173\n",
      "- mean accuracy: 0.03125\n",
      "- now 291\n",
      "- mean loss: 0.01780139096081257\n",
      "- mean accuracy: 0.02734375\n",
      "- now 292\n",
      "- mean loss: 0.017834044992923737\n",
      "- mean accuracy: 0.02734375\n",
      "- now 293\n",
      "- mean loss: 0.01771078072488308\n",
      "- mean accuracy: 0.0234375\n",
      "- now 294\n",
      "- mean loss: 0.017828259617090225\n",
      "- mean accuracy: 0.01953125\n",
      "- now 295\n",
      "- mean loss: 0.017907559871673584\n",
      "- mean accuracy: 0.03125\n",
      "- now 296\n",
      "- mean loss: 0.017656248062849045\n",
      "- mean accuracy: 0.0390625\n",
      "- now 297\n",
      "- mean loss: 0.017769774422049522\n",
      "- mean accuracy: 0.03515625\n",
      "- now 298\n",
      "- mean loss: 0.01777598448097706\n",
      "- mean accuracy: 0.02734375\n",
      "- now 299\n",
      "- mean loss: 0.01802423596382141\n",
      "- mean accuracy: 0.015625\n",
      "- now 300\n",
      "- mean loss: 0.017929334193468094\n",
      "- mean accuracy: 0.03125\n",
      "- now 301\n",
      "- mean loss: 0.01781497895717621\n",
      "- mean accuracy: 0.0390625\n",
      "- now 302\n",
      "- mean loss: 0.017851997166872025\n",
      "- mean accuracy: 0.0234375\n",
      "- now 303\n",
      "- mean loss: 0.01849154382944107\n",
      "- mean accuracy: 0.0546875\n",
      "- now 304\n",
      "- mean loss: 0.01790904998779297\n",
      "- mean accuracy: 0.0390625\n",
      "- now 305\n",
      "- mean loss: 0.01800757274031639\n",
      "- mean accuracy: 0.04296875\n",
      "- now 306\n",
      "- mean loss: 0.017954647541046143\n",
      "- mean accuracy: 0.046875\n",
      "- now 307\n",
      "- mean loss: 0.017869198694825172\n",
      "- mean accuracy: 0.03515625\n",
      "- now 308\n",
      "- mean loss: 0.018194282427430153\n",
      "- mean accuracy: 0.02734375\n",
      "- now 309\n",
      "- mean loss: 0.017779935151338577\n",
      "- mean accuracy: 0.0390625\n",
      "- now 310\n",
      "- mean loss: 0.01789213716983795\n",
      "- mean accuracy: 0.00390625\n",
      "- now 311\n",
      "- mean loss: 0.017933743074536324\n",
      "- mean accuracy: 0.01953125\n",
      "- now 312\n",
      "- mean loss: 0.01777368225157261\n",
      "- mean accuracy: 0.0234375\n",
      "- now 313\n",
      "- mean loss: 0.01769847981631756\n",
      "- mean accuracy: 0.03515625\n",
      "- now 314\n",
      "- mean loss: 0.017602188512682915\n",
      "- mean accuracy: 0.015625\n",
      "- now 315\n",
      "- mean loss: 0.01783495396375656\n",
      "- mean accuracy: 0.01953125\n",
      "- now 316\n",
      "- mean loss: 0.017613064497709274\n",
      "- mean accuracy: 0.03515625\n",
      "- now 317\n",
      "- mean loss: 0.017360761761665344\n",
      "- mean accuracy: 0.02734375\n",
      "- now 318\n",
      "- mean loss: 0.017520776018500328\n",
      "- mean accuracy: 0.0234375\n",
      "- now 319\n",
      "- mean loss: 0.01750503107905388\n",
      "- mean accuracy: 0.0234375\n",
      "- now 320\n",
      "- mean loss: 0.017537454143166542\n",
      "- mean accuracy: 0.0234375\n",
      "- now 321\n",
      "- mean loss: 0.01772778481245041\n",
      "- mean accuracy: 0.02734375\n",
      "- now 322\n",
      "- mean loss: 0.01757187210023403\n",
      "- mean accuracy: 0.02734375\n",
      "- now 323\n",
      "- mean loss: 0.01762762852013111\n",
      "- mean accuracy: 0.0234375\n",
      "- now 324\n",
      "- mean loss: 0.017589185386896133\n",
      "- mean accuracy: 0.01171875\n",
      "- now 325\n",
      "- mean loss: 0.017454853281378746\n",
      "- mean accuracy: 0.0234375\n",
      "- now 326\n",
      "- mean loss: 0.017635220661759377\n",
      "- mean accuracy: 0.015625\n",
      "- now 327\n",
      "- mean loss: 0.017444688826799393\n",
      "- mean accuracy: 0.04296875\n",
      "- now 328\n",
      "- mean loss: 0.01755983941257\n",
      "- mean accuracy: 0.03125\n",
      "- now 329\n",
      "- mean loss: 0.017427608370780945\n",
      "- mean accuracy: 0.02734375\n",
      "- now 330\n",
      "- mean loss: 0.017360785976052284\n",
      "- mean accuracy: 0.0078125\n",
      "- now 331\n",
      "- mean loss: 0.017383715137839317\n",
      "- mean accuracy: 0.0234375\n",
      "- now 332\n",
      "- mean loss: 0.017459899187088013\n",
      "- mean accuracy: 0.01953125\n",
      "- now 333\n",
      "- mean loss: 0.0177325289696455\n",
      "- mean accuracy: 0.02734375\n",
      "- now 334\n",
      "- mean loss: 0.01733395829796791\n",
      "- mean accuracy: 0.0234375\n",
      "- now 335\n",
      "- mean loss: 0.01749025285243988\n",
      "- mean accuracy: 0.0390625\n",
      "- now 336\n",
      "- mean loss: 0.01724144071340561\n",
      "- mean accuracy: 0.03515625\n",
      "- now 337\n",
      "- mean loss: 0.01730513758957386\n",
      "- mean accuracy: 0.03515625\n",
      "- now 338\n",
      "- mean loss: 0.017149752005934715\n",
      "- mean accuracy: 0.01953125\n",
      "- now 339\n",
      "- mean loss: 0.01737206056714058\n",
      "- mean accuracy: 0.03125\n",
      "- now 340\n",
      "- mean loss: 0.01728851906955242\n",
      "- mean accuracy: 0.01953125\n",
      "- now 341\n",
      "- mean loss: 0.01714341901242733\n",
      "- mean accuracy: 0.02734375\n",
      "- now 342\n",
      "- mean loss: 0.017545638605952263\n",
      "- mean accuracy: 0.0390625\n",
      "- now 343\n",
      "- mean loss: 0.01742546632885933\n",
      "- mean accuracy: 0.02734375\n",
      "- now 344\n",
      "- mean loss: 0.0174543596804142\n",
      "- mean accuracy: 0.0234375\n",
      "- now 345\n",
      "- mean loss: 0.017266863957047462\n",
      "- mean accuracy: 0.01953125\n",
      "- now 346\n",
      "- mean loss: 0.017342297360301018\n",
      "- mean accuracy: 0.0234375\n",
      "- now 347\n",
      "- mean loss: 0.01735001429915428\n",
      "- mean accuracy: 0.0078125\n",
      "- now 348\n",
      "- mean loss: 0.017366359010338783\n",
      "- mean accuracy: 0.04296875\n",
      "- now 349\n",
      "- mean loss: 0.01704719290137291\n",
      "- mean accuracy: 0.03515625\n",
      "- now 350\n",
      "- mean loss: 0.017132466658949852\n",
      "- mean accuracy: 0.046875\n",
      "- now 351\n",
      "- mean loss: 0.017370624467730522\n",
      "- mean accuracy: 0.0390625\n",
      "- now 352\n",
      "- mean loss: 0.017290761694312096\n",
      "- mean accuracy: 0.0234375\n",
      "- now 353\n",
      "- mean loss: 0.01738228090107441\n",
      "- mean accuracy: 0.02734375\n",
      "- now 354\n",
      "- mean loss: 0.01739194430410862\n",
      "- mean accuracy: 0.0234375\n",
      "- now 355\n",
      "- mean loss: 0.01725284568965435\n",
      "- mean accuracy: 0.0390625\n",
      "- now 356\n",
      "- mean loss: 0.017291247844696045\n",
      "- mean accuracy: 0.0390625\n",
      "- now 357\n",
      "- mean loss: 0.01673213206231594\n",
      "- mean accuracy: 0.03125\n",
      "- now 358\n",
      "- mean loss: 0.01741277426481247\n",
      "- mean accuracy: 0.02734375\n",
      "- now 359\n",
      "- mean loss: 0.017579566687345505\n",
      "- mean accuracy: 0.03125\n",
      "- now 360\n",
      "- mean loss: 0.01747223362326622\n",
      "- mean accuracy: 0.01171875\n",
      "- now 361\n",
      "- mean loss: 0.01748293824493885\n",
      "- mean accuracy: 0.05078125\n",
      "- now 362\n",
      "- mean loss: 0.017395567148923874\n",
      "- mean accuracy: 0.0234375\n",
      "- now 363\n",
      "- mean loss: 0.017236609011888504\n",
      "- mean accuracy: 0.0234375\n",
      "- now 364\n",
      "- mean loss: 0.017329849302768707\n",
      "- mean accuracy: 0.0234375\n",
      "- now 365\n",
      "- mean loss: 0.017400195822119713\n",
      "- mean accuracy: 0.02734375\n",
      "- now 366\n",
      "- mean loss: 0.017215711995959282\n",
      "- mean accuracy: 0.046875\n",
      "- now 367\n",
      "- mean loss: 0.017285607755184174\n",
      "- mean accuracy: 0.03125\n",
      "- now 368\n",
      "- mean loss: 0.01720076985657215\n",
      "- mean accuracy: 0.0390625\n",
      "- now 369\n",
      "- mean loss: 0.01726061850786209\n",
      "- mean accuracy: 0.02734375\n",
      "- now 370\n",
      "- mean loss: 0.0173468180000782\n",
      "- mean accuracy: 0.03125\n",
      "- now 371\n",
      "- mean loss: 0.01729785092175007\n",
      "- mean accuracy: 0.03515625\n",
      "- now 372\n",
      "- mean loss: 0.017563143745064735\n",
      "- mean accuracy: 0.03125\n",
      "- now 373\n",
      "- mean loss: 0.017778657376766205\n",
      "- mean accuracy: 0.015625\n",
      "- now 374\n",
      "- mean loss: 0.01737644523382187\n",
      "- mean accuracy: 0.03125\n",
      "- now 375\n",
      "- mean loss: 0.017097026109695435\n",
      "- mean accuracy: 0.03515625\n",
      "- now 376\n",
      "- mean loss: 0.017147602513432503\n",
      "- mean accuracy: 0.02734375\n",
      "- now 377\n",
      "- mean loss: 0.017108840867877007\n",
      "- mean accuracy: 0.01953125\n",
      "- now 378\n",
      "- mean loss: 0.017220523208379745\n",
      "- mean accuracy: 0.0390625\n",
      "- now 379\n",
      "- mean loss: 0.017318638041615486\n",
      "- mean accuracy: 0.01953125\n",
      "- now 380\n",
      "- mean loss: 0.01746358722448349\n",
      "- mean accuracy: 0.02734375\n",
      "- now 381\n",
      "- mean loss: 0.01748192310333252\n",
      "- mean accuracy: 0.01953125\n",
      "- now 382\n",
      "- mean loss: 0.01752496138215065\n",
      "- mean accuracy: 0.03515625\n",
      "- now 383\n",
      "- mean loss: 0.017429843544960022\n",
      "- mean accuracy: 0.02734375\n",
      "- now 384\n",
      "- mean loss: 0.017584891989827156\n",
      "- mean accuracy: 0.03125\n",
      "- now 385\n",
      "- mean loss: 0.017860066145658493\n",
      "- mean accuracy: 0.015625\n",
      "- now 386\n",
      "- mean loss: 0.0177402812987566\n",
      "- mean accuracy: 0.03515625\n",
      "- now 387\n",
      "- mean loss: 0.017859216779470444\n",
      "- mean accuracy: 0.03125\n",
      "- now 388\n",
      "- mean loss: 0.017979659140110016\n",
      "- mean accuracy: 0.01953125\n",
      "- now 389\n",
      "- mean loss: 0.017671076580882072\n",
      "- mean accuracy: 0.03125\n",
      "- now 390\n",
      "- mean loss: 0.017466366291046143\n",
      "- mean accuracy: 0.01953125\n",
      "- now 391\n",
      "- mean loss: 0.017385445535182953\n",
      "- mean accuracy: 0.03125\n",
      "- now 392\n",
      "- mean loss: 0.017252903431653976\n",
      "- mean accuracy: 0.03515625\n",
      "- now 393\n",
      "- mean loss: 0.01739511452615261\n",
      "- mean accuracy: 0.03515625\n",
      "- now 394\n",
      "- mean loss: 0.017441153526306152\n",
      "- mean accuracy: 0.03125\n",
      "- now 395\n",
      "- mean loss: 0.01750042289495468\n",
      "- mean accuracy: 0.03125\n",
      "- now 396\n",
      "- mean loss: 0.01761448010802269\n",
      "- mean accuracy: 0.01953125\n",
      "- now 397\n",
      "- mean loss: 0.017498744651675224\n",
      "- mean accuracy: 0.03515625\n",
      "- now 398\n",
      "- mean loss: 0.017474157735705376\n",
      "- mean accuracy: 0.0234375\n",
      "- now 399\n",
      "- mean loss: 0.017613833770155907\n",
      "- mean accuracy: 0.02734375\n",
      "- now 400\n",
      "- mean loss: 0.017528535798192024\n",
      "- mean accuracy: 0.015625\n",
      "- now 401\n",
      "- mean loss: 0.017554130405187607\n",
      "- mean accuracy: 0.03515625\n",
      "- now 402\n",
      "- mean loss: 0.017412154003977776\n",
      "- mean accuracy: 0.0390625\n",
      "- now 403\n",
      "- mean loss: 0.01765177957713604\n",
      "- mean accuracy: 0.02734375\n",
      "- now 404\n",
      "- mean loss: 0.017761273309588432\n",
      "- mean accuracy: 0.03125\n",
      "- now 405\n",
      "- mean loss: 0.017775796353816986\n",
      "- mean accuracy: 0.0234375\n",
      "- now 406\n",
      "- mean loss: 0.017381977289915085\n",
      "- mean accuracy: 0.02734375\n",
      "- now 407\n",
      "- mean loss: 0.017574768513441086\n",
      "- mean accuracy: 0.01953125\n",
      "- now 408\n",
      "- mean loss: 0.017298908904194832\n",
      "- mean accuracy: 0.03515625\n",
      "- now 409\n",
      "- mean loss: 0.01751813478767872\n",
      "- mean accuracy: 0.03515625\n",
      "- now 410\n",
      "- mean loss: 0.01764485612511635\n",
      "- mean accuracy: 0.015625\n",
      "- now 411\n",
      "- mean loss: 0.0173328910022974\n",
      "- mean accuracy: 0.01953125\n",
      "- now 412\n",
      "- mean loss: 0.01741786301136017\n",
      "- mean accuracy: 0.03515625\n",
      "- now 413\n",
      "- mean loss: 0.01764868199825287\n",
      "- mean accuracy: 0.03125\n",
      "- now 414\n",
      "- mean loss: 0.017347432672977448\n",
      "- mean accuracy: 0.0234375\n",
      "- now 415\n",
      "- mean loss: 0.017464861273765564\n",
      "- mean accuracy: 0.0390625\n",
      "- now 416\n",
      "- mean loss: 0.017224328592419624\n",
      "- mean accuracy: 0.03125\n",
      "- now 417\n",
      "- mean loss: 0.01752910017967224\n",
      "- mean accuracy: 0.02734375\n",
      "- now 418\n",
      "- mean loss: 0.01739831641316414\n",
      "- mean accuracy: 0.02734375\n",
      "- now 419\n",
      "- mean loss: 0.01758226752281189\n",
      "- mean accuracy: 0.01171875\n",
      "- now 420\n",
      "- mean loss: 0.01764320768415928\n",
      "- mean accuracy: 0.01953125\n",
      "- now 421\n",
      "- mean loss: 0.017542889341711998\n",
      "- mean accuracy: 0.03515625\n",
      "- now 422\n",
      "- mean loss: 0.017788533121347427\n",
      "- mean accuracy: 0.02734375\n",
      "- now 423\n",
      "- mean loss: 0.01730760745704174\n",
      "- mean accuracy: 0.0390625\n",
      "- now 424\n",
      "- mean loss: 0.017441080883145332\n",
      "- mean accuracy: 0.0390625\n",
      "- now 425\n",
      "- mean loss: 0.017539264634251595\n",
      "- mean accuracy: 0.05859375\n",
      "- now 426\n",
      "- mean loss: 0.017424723133444786\n",
      "- mean accuracy: 0.02734375\n",
      "- now 427\n",
      "- mean loss: 0.017385564744472504\n",
      "- mean accuracy: 0.03515625\n",
      "- now 428\n",
      "- mean loss: 0.017200151458382607\n",
      "- mean accuracy: 0.0234375\n",
      "- now 429\n",
      "- mean loss: 0.017420519143342972\n",
      "- mean accuracy: 0.03125\n",
      "- now 430\n",
      "- mean loss: 0.017239103093743324\n",
      "- mean accuracy: 0.0234375\n",
      "- now 431\n",
      "- mean loss: 0.017657646909356117\n",
      "- mean accuracy: 0.0234375\n",
      "- now 432\n",
      "- mean loss: 0.01747838407754898\n",
      "- mean accuracy: 0.03125\n",
      "- now 433\n",
      "- mean loss: 0.017560692504048347\n",
      "- mean accuracy: 0.03125\n",
      "- now 434\n",
      "- mean loss: 0.017697488889098167\n",
      "- mean accuracy: 0.0390625\n",
      "- now 435\n",
      "- mean loss: 0.01743176020681858\n",
      "- mean accuracy: 0.02734375\n",
      "- now 436\n",
      "- mean loss: 0.017597496509552002\n",
      "- mean accuracy: 0.02734375\n",
      "- now 437\n",
      "- mean loss: 0.017584525048732758\n",
      "- mean accuracy: 0.02734375\n",
      "- now 438\n",
      "- mean loss: 0.01745849847793579\n",
      "- mean accuracy: 0.03515625\n",
      "- now 439\n",
      "- mean loss: 0.017217272892594337\n",
      "- mean accuracy: 0.03515625\n",
      "- now 440\n",
      "- mean loss: 0.01727353036403656\n",
      "- mean accuracy: 0.03125\n",
      "- now 441\n",
      "- mean loss: 0.017064152285456657\n",
      "- mean accuracy: 0.03515625\n",
      "- now 442\n",
      "- mean loss: 0.01746021956205368\n",
      "- mean accuracy: 0.03515625\n",
      "- now 443\n",
      "- mean loss: 0.01713167130947113\n",
      "- mean accuracy: 0.02734375\n",
      "- now 444\n",
      "- mean loss: 0.017364172264933586\n",
      "- mean accuracy: 0.046875\n",
      "- now 445\n",
      "- mean loss: 0.017318081110715866\n",
      "- mean accuracy: 0.0390625\n",
      "- now 446\n",
      "- mean loss: 0.017040196806192398\n",
      "- mean accuracy: 0.046875\n",
      "- now 447\n",
      "- mean loss: 0.017178727313876152\n",
      "- mean accuracy: 0.03515625\n",
      "- now 448\n",
      "- mean loss: 0.01728268526494503\n",
      "- mean accuracy: 0.03125\n",
      "- now 449\n",
      "- mean loss: 0.017370199784636497\n",
      "- mean accuracy: 0.03125\n",
      "- now 450\n",
      "- mean loss: 0.017586886882781982\n",
      "- mean accuracy: 0.02734375\n",
      "- now 451\n",
      "- mean loss: 0.017060978338122368\n",
      "- mean accuracy: 0.03515625\n",
      "- now 452\n",
      "- mean loss: 0.01713220402598381\n",
      "- mean accuracy: 0.0546875\n",
      "- now 453\n",
      "- mean loss: 0.016977641731500626\n",
      "- mean accuracy: 0.046875\n",
      "- now 454\n",
      "- mean loss: 0.017042091116309166\n",
      "- mean accuracy: 0.046875\n",
      "- now 455\n",
      "- mean loss: 0.017061952501535416\n",
      "- mean accuracy: 0.03125\n",
      "- now 456\n",
      "- mean loss: 0.01711099036037922\n",
      "- mean accuracy: 0.02734375\n",
      "- now 457\n",
      "- mean loss: 0.01701831817626953\n",
      "- mean accuracy: 0.05078125\n",
      "- now 458\n",
      "- mean loss: 0.016971437260508537\n",
      "- mean accuracy: 0.02734375\n",
      "- now 459\n",
      "- mean loss: 0.01691422611474991\n",
      "- mean accuracy: 0.03515625\n",
      "- now 460\n",
      "- mean loss: 0.016862407326698303\n",
      "- mean accuracy: 0.05078125\n",
      "- now 461\n",
      "- mean loss: 0.016768595203757286\n",
      "- mean accuracy: 0.03515625\n",
      "- now 462\n",
      "- mean loss: 0.01690525934100151\n",
      "- mean accuracy: 0.02734375\n",
      "- now 463\n",
      "- mean loss: 0.016933195292949677\n",
      "- mean accuracy: 0.046875\n",
      "- now 464\n",
      "- mean loss: 0.017201092094182968\n",
      "- mean accuracy: 0.0234375\n",
      "- now 465\n",
      "- mean loss: 0.017110314220190048\n",
      "- mean accuracy: 0.0390625\n",
      "- now 466\n",
      "- mean loss: 0.01672384701669216\n",
      "- mean accuracy: 0.05859375\n",
      "- now 467\n",
      "- mean loss: 0.017012789845466614\n",
      "- mean accuracy: 0.05078125\n",
      "- now 468\n",
      "- mean loss: 0.017205243930220604\n",
      "- mean accuracy: 0.03125\n",
      "- now 469\n",
      "- mean loss: 0.01704513654112816\n",
      "- mean accuracy: 0.04296875\n",
      "- now 470\n",
      "- mean loss: 0.016826773062348366\n",
      "- mean accuracy: 0.03125\n",
      "- now 471\n",
      "- mean loss: 0.01659921556711197\n",
      "- mean accuracy: 0.03515625\n",
      "- now 472\n",
      "- mean loss: 0.016986936330795288\n",
      "- mean accuracy: 0.04296875\n",
      "- now 473\n",
      "- mean loss: 0.016876451671123505\n",
      "- mean accuracy: 0.0390625\n",
      "- now 474\n",
      "- mean loss: 0.016836853697896004\n",
      "- mean accuracy: 0.05078125\n",
      "- now 475\n",
      "- mean loss: 0.017254339531064034\n",
      "- mean accuracy: 0.0390625\n",
      "- now 476\n",
      "- mean loss: 0.017118539661169052\n",
      "- mean accuracy: 0.03515625\n",
      "- now 477\n",
      "- mean loss: 0.016998667269945145\n",
      "- mean accuracy: 0.0390625\n",
      "- now 478\n",
      "- mean loss: 0.016972465440630913\n",
      "- mean accuracy: 0.0390625\n",
      "- now 479\n",
      "- mean loss: 0.0170628409832716\n",
      "- mean accuracy: 0.015625\n",
      "- now 480\n",
      "- mean loss: 0.01657699979841709\n",
      "- mean accuracy: 0.03125\n",
      "- now 481\n",
      "- mean loss: 0.017026813700795174\n",
      "- mean accuracy: 0.03125\n",
      "- now 482\n",
      "- mean loss: 0.016891855746507645\n",
      "- mean accuracy: 0.0234375\n",
      "- now 483\n",
      "- mean loss: 0.016773397102952003\n",
      "- mean accuracy: 0.05078125\n",
      "- now 484\n",
      "- mean loss: 0.016590315848588943\n",
      "- mean accuracy: 0.0234375\n",
      "- now 485\n",
      "- mean loss: 0.01667000912129879\n",
      "- mean accuracy: 0.01953125\n",
      "- now 486\n",
      "- mean loss: 0.015971601009368896\n",
      "- mean accuracy: 0.02734375\n",
      "- now 487\n",
      "- mean loss: 0.016649603843688965\n",
      "- mean accuracy: 0.04296875\n",
      "- now 488\n",
      "- mean loss: 0.016500428318977356\n",
      "- mean accuracy: 0.0390625\n",
      "- now 489\n",
      "- mean loss: 0.016637735068798065\n",
      "- mean accuracy: 0.03515625\n",
      "- now 490\n",
      "- mean loss: 0.01648934930562973\n",
      "- mean accuracy: 0.04296875\n",
      "- now 491\n",
      "- mean loss: 0.016867434605956078\n",
      "- mean accuracy: 0.02734375\n",
      "- now 492\n",
      "- mean loss: 0.016421213746070862\n",
      "- mean accuracy: 0.0234375\n",
      "- now 493\n",
      "- mean loss: 0.01629355549812317\n",
      "- mean accuracy: 0.0625\n",
      "- now 494\n",
      "- mean loss: 0.016736719757318497\n",
      "- mean accuracy: 0.03125\n",
      "- now 495\n",
      "- mean loss: 0.01640111394226551\n",
      "- mean accuracy: 0.05078125\n",
      "- now 496\n",
      "- mean loss: 0.015971651300787926\n",
      "- mean accuracy: 0.0390625\n",
      "- now 497\n",
      "- mean loss: 0.01619078777730465\n",
      "- mean accuracy: 0.03125\n",
      "- now 498\n",
      "- mean loss: 0.01630818285048008\n",
      "- mean accuracy: 0.05078125\n",
      "- now 499\n",
      "- mean loss: 0.016196945682168007\n",
      "- mean accuracy: 0.06640625\n",
      "- now 500\n",
      "- mean loss: 0.016306519508361816\n",
      "- mean accuracy: 0.0390625\n",
      "- now 501\n",
      "- mean loss: 0.01625855639576912\n",
      "- mean accuracy: 0.02734375\n",
      "- now 502\n",
      "- mean loss: 0.016341373324394226\n",
      "- mean accuracy: 0.03515625\n",
      "- now 503\n",
      "- mean loss: 0.016380533576011658\n",
      "- mean accuracy: 0.0546875\n",
      "- now 504\n",
      "- mean loss: 0.016452370211482048\n",
      "- mean accuracy: 0.046875\n",
      "- now 505\n",
      "- mean loss: 0.016046280041337013\n",
      "- mean accuracy: 0.02734375\n",
      "- now 506\n",
      "- mean loss: 0.01625174656510353\n",
      "- mean accuracy: 0.02734375\n",
      "- now 507\n",
      "- mean loss: 0.016149388626217842\n",
      "- mean accuracy: 0.05078125\n",
      "- now 508\n",
      "- mean loss: 0.016343653202056885\n",
      "- mean accuracy: 0.046875\n",
      "- now 509\n",
      "- mean loss: 0.016341213136911392\n",
      "- mean accuracy: 0.05859375\n",
      "- now 510\n",
      "- mean loss: 0.016865484416484833\n",
      "- mean accuracy: 0.02734375\n",
      "- now 511\n",
      "- mean loss: 0.016428334638476372\n",
      "- mean accuracy: 0.03125\n",
      "- now 512\n",
      "- mean loss: 0.016346974298357964\n",
      "- mean accuracy: 0.06640625\n",
      "- now 513\n",
      "- mean loss: 0.016123153269290924\n",
      "- mean accuracy: 0.05078125\n",
      "- now 514\n",
      "- mean loss: 0.016560832038521767\n",
      "- mean accuracy: 0.04296875\n",
      "- now 515\n",
      "- mean loss: 0.016562528908252716\n",
      "- mean accuracy: 0.04296875\n",
      "- now 516\n",
      "- mean loss: 0.01610805094242096\n",
      "- mean accuracy: 0.03125\n",
      "- now 517\n",
      "- mean loss: 0.01655697077512741\n",
      "- mean accuracy: 0.03125\n",
      "- now 518\n",
      "- mean loss: 0.016479134559631348\n",
      "- mean accuracy: 0.01953125\n",
      "- now 519\n",
      "- mean loss: 0.01644986681640148\n",
      "- mean accuracy: 0.0390625\n",
      "- now 520\n",
      "- mean loss: 0.016287988051772118\n",
      "- mean accuracy: 0.02734375\n",
      "- now 521\n",
      "- mean loss: 0.016162361949682236\n",
      "- mean accuracy: 0.04296875\n",
      "- now 522\n",
      "- mean loss: 0.016396639868617058\n",
      "- mean accuracy: 0.05859375\n",
      "- now 523\n",
      "- mean loss: 0.0165487639605999\n",
      "- mean accuracy: 0.0390625\n",
      "- now 524\n",
      "- mean loss: 0.01671696826815605\n",
      "- mean accuracy: 0.03515625\n",
      "- now 525\n",
      "- mean loss: 0.016332712024450302\n",
      "- mean accuracy: 0.078125\n",
      "- now 526\n",
      "- mean loss: 0.016402844339609146\n",
      "- mean accuracy: 0.04296875\n",
      "- now 527\n",
      "- mean loss: 0.016549749299883842\n",
      "- mean accuracy: 0.05078125\n",
      "- now 528\n",
      "- mean loss: 0.016345491632819176\n",
      "- mean accuracy: 0.0703125\n",
      "- now 529\n",
      "- mean loss: 0.016405446454882622\n",
      "- mean accuracy: 0.05078125\n",
      "- now 530\n",
      "- mean loss: 0.01667785458266735\n",
      "- mean accuracy: 0.03125\n",
      "- now 531\n",
      "- mean loss: 0.016278842464089394\n",
      "- mean accuracy: 0.04296875\n",
      "- now 532\n",
      "- mean loss: 0.016338692978024483\n",
      "- mean accuracy: 0.03125\n",
      "- now 533\n",
      "- mean loss: 0.01595475524663925\n",
      "- mean accuracy: 0.0390625\n",
      "- now 534\n",
      "- mean loss: 0.015951912850141525\n",
      "- mean accuracy: 0.046875\n",
      "- now 535\n",
      "- mean loss: 0.01608593761920929\n",
      "- mean accuracy: 0.0546875\n",
      "- now 536\n",
      "- mean loss: 0.015890231356024742\n",
      "- mean accuracy: 0.046875\n",
      "- now 537\n",
      "- mean loss: 0.015905942767858505\n",
      "- mean accuracy: 0.05859375\n",
      "- now 538\n",
      "- mean loss: 0.01635660231113434\n",
      "- mean accuracy: 0.04296875\n",
      "- now 539\n",
      "- mean loss: 0.016110016033053398\n",
      "- mean accuracy: 0.046875\n",
      "- now 540\n",
      "- mean loss: 0.01607779785990715\n",
      "- mean accuracy: 0.04296875\n",
      "- now 541\n",
      "- mean loss: 0.016210388392210007\n",
      "- mean accuracy: 0.04296875\n",
      "- now 542\n",
      "- mean loss: 0.016280561685562134\n",
      "- mean accuracy: 0.03515625\n",
      "- now 543\n",
      "- mean loss: 0.016526805236935616\n",
      "- mean accuracy: 0.03515625\n",
      "- now 544\n",
      "- mean loss: 0.01596825011074543\n",
      "- mean accuracy: 0.04296875\n",
      "- now 545\n",
      "- mean loss: 0.016341090202331543\n",
      "- mean accuracy: 0.0390625\n",
      "- now 546\n",
      "- mean loss: 0.016250794753432274\n",
      "- mean accuracy: 0.05859375\n",
      "- now 547\n",
      "- mean loss: 0.016176380217075348\n",
      "- mean accuracy: 0.06640625\n",
      "- now 548\n",
      "- mean loss: 0.016065288335084915\n",
      "- mean accuracy: 0.04296875\n",
      "- now 549\n",
      "- mean loss: 0.016388660296797752\n",
      "- mean accuracy: 0.03515625\n",
      "- now 550\n",
      "- mean loss: 0.0159588772803545\n",
      "- mean accuracy: 0.046875\n",
      "- now 551\n",
      "- mean loss: 0.01608094945549965\n",
      "- mean accuracy: 0.03125\n",
      "- now 552\n",
      "- mean loss: 0.016255009919404984\n",
      "- mean accuracy: 0.04296875\n",
      "- now 553\n",
      "- mean loss: 0.016195345669984818\n",
      "- mean accuracy: 0.05078125\n",
      "- now 554\n",
      "- mean loss: 0.015748418867588043\n",
      "- mean accuracy: 0.03125\n",
      "- now 555\n",
      "- mean loss: 0.015920333564281464\n",
      "- mean accuracy: 0.03515625\n",
      "- now 556\n",
      "- mean loss: 0.016148291528224945\n",
      "- mean accuracy: 0.046875\n",
      "- now 557\n",
      "- mean loss: 0.016047626733779907\n",
      "- mean accuracy: 0.0234375\n",
      "- now 558\n",
      "- mean loss: 0.0159420445561409\n",
      "- mean accuracy: 0.0390625\n",
      "- now 559\n",
      "- mean loss: 0.016018114984035492\n",
      "- mean accuracy: 0.04296875\n",
      "- now 560\n",
      "- mean loss: 0.016163930296897888\n",
      "- mean accuracy: 0.05859375\n",
      "- now 561\n",
      "- mean loss: 0.01589716412127018\n",
      "- mean accuracy: 0.0390625\n",
      "- now 562\n",
      "- mean loss: 0.01613900251686573\n",
      "- mean accuracy: 0.03515625\n",
      "- now 563\n",
      "- mean loss: 0.01591486856341362\n",
      "- mean accuracy: 0.05078125\n",
      "- now 564\n",
      "- mean loss: 0.01607855223119259\n",
      "- mean accuracy: 0.04296875\n",
      "- now 565\n",
      "- mean loss: 0.01581457257270813\n",
      "- mean accuracy: 0.0546875\n",
      "- now 566\n",
      "- mean loss: 0.01612089015543461\n",
      "- mean accuracy: 0.046875\n",
      "- now 567\n",
      "- mean loss: 0.016433976590633392\n",
      "- mean accuracy: 0.046875\n",
      "- now 568\n",
      "- mean loss: 0.01668023318052292\n",
      "- mean accuracy: 0.05078125\n",
      "- now 569\n",
      "- mean loss: 0.016570022329688072\n",
      "- mean accuracy: 0.03515625\n",
      "- now 570\n",
      "- mean loss: 0.016704095527529716\n",
      "- mean accuracy: 0.04296875\n",
      "- now 571\n",
      "- mean loss: 0.016526350751519203\n",
      "- mean accuracy: 0.046875\n",
      "- now 572\n",
      "- mean loss: 0.016530003398656845\n",
      "- mean accuracy: 0.0625\n",
      "- now 573\n",
      "- mean loss: 0.016545452177524567\n",
      "- mean accuracy: 0.05859375\n",
      "- now 574\n",
      "- mean loss: 0.016656160354614258\n",
      "- mean accuracy: 0.0390625\n",
      "- now 575\n",
      "- mean loss: 0.01698804460465908\n",
      "- mean accuracy: 0.03515625\n",
      "- now 576\n",
      "- mean loss: 0.016563890501856804\n",
      "- mean accuracy: 0.04296875\n",
      "- now 577\n",
      "- mean loss: 0.016646673902869225\n",
      "- mean accuracy: 0.02734375\n",
      "- now 578\n",
      "- mean loss: 0.016314424574375153\n",
      "- mean accuracy: 0.04296875\n",
      "- now 579\n",
      "- mean loss: 0.016274400055408478\n",
      "- mean accuracy: 0.0546875\n",
      "- now 580\n",
      "- mean loss: 0.016342874616384506\n",
      "- mean accuracy: 0.046875\n",
      "- now 581\n",
      "- mean loss: 0.01603342406451702\n",
      "- mean accuracy: 0.0625\n",
      "- now 582\n",
      "- mean loss: 0.016139931976795197\n",
      "- mean accuracy: 0.05859375\n",
      "- now 583\n",
      "- mean loss: 0.016191350296139717\n",
      "- mean accuracy: 0.02734375\n",
      "- now 584\n",
      "- mean loss: 0.016206929460167885\n",
      "- mean accuracy: 0.03515625\n",
      "- now 585\n",
      "- mean loss: 0.01608070731163025\n",
      "- mean accuracy: 0.03515625\n",
      "- now 586\n",
      "- mean loss: 0.016195351257920265\n",
      "- mean accuracy: 0.0390625\n",
      "- now 587\n",
      "- mean loss: 0.016378087922930717\n",
      "- mean accuracy: 0.03125\n",
      "- now 588\n",
      "- mean loss: 0.015999963507056236\n",
      "- mean accuracy: 0.0390625\n",
      "- now 589\n",
      "- mean loss: 0.016114572063088417\n",
      "- mean accuracy: 0.046875\n",
      "- now 590\n",
      "- mean loss: 0.016445450484752655\n",
      "- mean accuracy: 0.05859375\n",
      "- now 591\n",
      "- mean loss: 0.01637149043381214\n",
      "- mean accuracy: 0.0625\n",
      "- now 592\n",
      "- mean loss: 0.01629670523107052\n",
      "- mean accuracy: 0.05078125\n",
      "- now 593\n",
      "- mean loss: 0.01618686132133007\n",
      "- mean accuracy: 0.0546875\n",
      "- now 594\n",
      "- mean loss: 0.01617673598229885\n",
      "- mean accuracy: 0.01953125\n",
      "- now 595\n",
      "- mean loss: 0.01571447029709816\n",
      "- mean accuracy: 0.0390625\n",
      "- now 596\n",
      "- mean loss: 0.016331568360328674\n",
      "- mean accuracy: 0.01953125\n",
      "- now 597\n",
      "- mean loss: 0.016345541924238205\n",
      "- mean accuracy: 0.0390625\n",
      "- now 598\n",
      "- mean loss: 0.016580821946263313\n",
      "- mean accuracy: 0.03515625\n",
      "- now 599\n",
      "- mean loss: 0.016563793644309044\n",
      "- mean accuracy: 0.04296875\n",
      "- now 600\n",
      "- mean loss: 0.016187099739909172\n",
      "- mean accuracy: 0.05859375\n",
      "- now 601\n",
      "- mean loss: 0.01604142226278782\n",
      "- mean accuracy: 0.0546875\n",
      "- now 602\n",
      "- mean loss: 0.016487468034029007\n",
      "- mean accuracy: 0.0390625\n",
      "- now 603\n",
      "- mean loss: 0.016287093982100487\n",
      "- mean accuracy: 0.04296875\n",
      "- now 604\n",
      "- mean loss: 0.016079913824796677\n",
      "- mean accuracy: 0.0390625\n",
      "- now 605\n",
      "- mean loss: 0.015987681224942207\n",
      "- mean accuracy: 0.0390625\n",
      "- now 606\n",
      "- mean loss: 0.016011180356144905\n",
      "- mean accuracy: 0.05859375\n",
      "- now 607\n",
      "- mean loss: 0.01634734869003296\n",
      "- mean accuracy: 0.046875\n",
      "- now 608\n",
      "- mean loss: 0.016145911067724228\n",
      "- mean accuracy: 0.0625\n",
      "- now 609\n",
      "- mean loss: 0.016183611005544662\n",
      "- mean accuracy: 0.03515625\n",
      "- now 610\n",
      "- mean loss: 0.016279399394989014\n",
      "- mean accuracy: 0.05859375\n",
      "- now 611\n",
      "- mean loss: 0.016333185136318207\n",
      "- mean accuracy: 0.0546875\n",
      "- now 612\n",
      "- mean loss: 0.016422053799033165\n",
      "- mean accuracy: 0.05859375\n",
      "- now 613\n",
      "- mean loss: 0.015919076278805733\n",
      "- mean accuracy: 0.0859375\n",
      "- now 614\n",
      "- mean loss: 0.016278419643640518\n",
      "- mean accuracy: 0.05078125\n",
      "- now 615\n",
      "- mean loss: 0.016653655096888542\n",
      "- mean accuracy: 0.0546875\n",
      "- now 616\n",
      "- mean loss: 0.016714313998818398\n",
      "- mean accuracy: 0.0390625\n",
      "- now 617\n",
      "- mean loss: 0.016513535752892494\n",
      "- mean accuracy: 0.0546875\n",
      "- now 618\n",
      "- mean loss: 0.016452675685286522\n",
      "- mean accuracy: 0.0546875\n",
      "- now 619\n",
      "- mean loss: 0.016376197338104248\n",
      "- mean accuracy: 0.046875\n",
      "- now 620\n",
      "- mean loss: 0.01623978279531002\n",
      "- mean accuracy: 0.046875\n",
      "- now 621\n",
      "- mean loss: 0.016443710774183273\n",
      "- mean accuracy: 0.0625\n",
      "- now 622\n",
      "- mean loss: 0.016323797404766083\n",
      "- mean accuracy: 0.05859375\n",
      "- now 623\n",
      "- mean loss: 0.01584184356033802\n",
      "- mean accuracy: 0.0703125\n",
      "- now 624\n",
      "- mean loss: 0.016202647238969803\n",
      "- mean accuracy: 0.05859375\n",
      "- now 625\n",
      "- mean loss: 0.016230136156082153\n",
      "- mean accuracy: 0.04296875\n",
      "- now 626\n",
      "- mean loss: 0.016169531270861626\n",
      "- mean accuracy: 0.078125\n",
      "- now 627\n",
      "- mean loss: 0.016035599634051323\n",
      "- mean accuracy: 0.0546875\n",
      "- now 628\n",
      "- mean loss: 0.01630556769669056\n",
      "- mean accuracy: 0.03515625\n",
      "- now 629\n",
      "- mean loss: 0.016405601054430008\n",
      "- mean accuracy: 0.05078125\n",
      "- now 630\n",
      "- mean loss: 0.016266031190752983\n",
      "- mean accuracy: 0.05859375\n",
      "- now 631\n",
      "- mean loss: 0.016287734732031822\n",
      "- mean accuracy: 0.05078125\n",
      "- now 632\n",
      "- mean loss: 0.016546275466680527\n",
      "- mean accuracy: 0.02734375\n",
      "- now 633\n",
      "- mean loss: 0.01633835770189762\n",
      "- mean accuracy: 0.0546875\n",
      "- now 634\n",
      "- mean loss: 0.01621231995522976\n",
      "- mean accuracy: 0.05078125\n",
      "- now 635\n",
      "- mean loss: 0.016225339844822884\n",
      "- mean accuracy: 0.05078125\n",
      "- now 636\n",
      "- mean loss: 0.0162951722741127\n",
      "- mean accuracy: 0.03515625\n",
      "- now 637\n",
      "- mean loss: 0.015973467379808426\n",
      "- mean accuracy: 0.03515625\n",
      "- now 638\n",
      "- mean loss: 0.015999097377061844\n",
      "- mean accuracy: 0.03515625\n",
      "- now 639\n",
      "- mean loss: 0.01602579653263092\n",
      "- mean accuracy: 0.0546875\n",
      "- now 640\n",
      "- mean loss: 0.015999196097254753\n",
      "- mean accuracy: 0.03125\n",
      "- now 641\n",
      "- mean loss: 0.015802472829818726\n",
      "- mean accuracy: 0.03515625\n",
      "- now 642\n",
      "- mean loss: 0.01579313911497593\n",
      "- mean accuracy: 0.046875\n",
      "- now 643\n",
      "- mean loss: 0.015734603628516197\n",
      "- mean accuracy: 0.06640625\n",
      "- now 644\n",
      "- mean loss: 0.015944037586450577\n",
      "- mean accuracy: 0.046875\n",
      "- now 645\n",
      "- mean loss: 0.015625713393092155\n",
      "- mean accuracy: 0.03515625\n",
      "- now 646\n",
      "- mean loss: 0.015730014070868492\n",
      "- mean accuracy: 0.03125\n",
      "- now 647\n",
      "- mean loss: 0.015728704631328583\n",
      "- mean accuracy: 0.04296875\n",
      "- now 648\n",
      "- mean loss: 0.015896670520305634\n",
      "- mean accuracy: 0.0625\n",
      "- now 649\n",
      "- mean loss: 0.01571880280971527\n",
      "- mean accuracy: 0.05859375\n",
      "- now 650\n",
      "- mean loss: 0.01608405075967312\n",
      "- mean accuracy: 0.0625\n",
      "- now 651\n",
      "- mean loss: 0.015822581946849823\n",
      "- mean accuracy: 0.05859375\n",
      "- now 652\n",
      "- mean loss: 0.015882795676589012\n",
      "- mean accuracy: 0.046875\n",
      "- now 653\n",
      "- mean loss: 0.015977634117007256\n",
      "- mean accuracy: 0.0390625\n",
      "- now 654\n",
      "- mean loss: 0.016042117029428482\n",
      "- mean accuracy: 0.05078125\n",
      "- now 655\n",
      "- mean loss: 0.015684079378843307\n",
      "- mean accuracy: 0.05859375\n",
      "- now 656\n",
      "- mean loss: 0.01600969024002552\n",
      "- mean accuracy: 0.05078125\n",
      "- now 657\n",
      "- mean loss: 0.015639519318938255\n",
      "- mean accuracy: 0.02734375\n",
      "- now 658\n",
      "- mean loss: 0.015883270651102066\n",
      "- mean accuracy: 0.05859375\n",
      "- now 659\n",
      "- mean loss: 0.016050271689891815\n",
      "- mean accuracy: 0.04296875\n",
      "- now 660\n",
      "- mean loss: 0.015983618795871735\n",
      "- mean accuracy: 0.05859375\n",
      "- now 661\n",
      "- mean loss: 0.01598588190972805\n",
      "- mean accuracy: 0.05859375\n",
      "- now 662\n",
      "- mean loss: 0.016156360507011414\n",
      "- mean accuracy: 0.0625\n",
      "- now 663\n",
      "- mean loss: 0.015985414385795593\n",
      "- mean accuracy: 0.04296875\n",
      "- now 664\n",
      "- mean loss: 0.016091153025627136\n",
      "- mean accuracy: 0.0625\n",
      "- now 665\n",
      "- mean loss: 0.015804365277290344\n",
      "- mean accuracy: 0.046875\n",
      "- now 666\n",
      "- mean loss: 0.016237545758485794\n",
      "- mean accuracy: 0.03515625\n",
      "- now 667\n",
      "- mean loss: 0.016127651557326317\n",
      "- mean accuracy: 0.03515625\n",
      "- now 668\n",
      "- mean loss: 0.016100140288472176\n",
      "- mean accuracy: 0.0390625\n",
      "- now 669\n",
      "- mean loss: 0.01600702852010727\n",
      "- mean accuracy: 0.06640625\n",
      "- now 670\n",
      "- mean loss: 0.015752708539366722\n",
      "- mean accuracy: 0.0546875\n",
      "- now 671\n",
      "- mean loss: 0.016098391264677048\n",
      "- mean accuracy: 0.0546875\n",
      "- now 672\n",
      "- mean loss: 0.01573833078145981\n",
      "- mean accuracy: 0.0625\n",
      "- now 673\n",
      "- mean loss: 0.01527668908238411\n",
      "- mean accuracy: 0.0625\n",
      "- now 674\n",
      "- mean loss: 0.015581767074763775\n",
      "- mean accuracy: 0.0625\n",
      "- now 675\n",
      "- mean loss: 0.016114255413413048\n",
      "- mean accuracy: 0.0546875\n",
      "- now 676\n",
      "- mean loss: 0.01644742116332054\n",
      "- mean accuracy: 0.04296875\n",
      "- now 677\n",
      "- mean loss: 0.016053684055805206\n",
      "- mean accuracy: 0.05078125\n",
      "- now 678\n",
      "- mean loss: 0.015646861866116524\n",
      "- mean accuracy: 0.0625\n",
      "- now 679\n",
      "- mean loss: 0.015648862347006798\n",
      "- mean accuracy: 0.04296875\n",
      "- now 680\n",
      "- mean loss: 0.015791695564985275\n",
      "- mean accuracy: 0.0625\n",
      "- now 681\n",
      "- mean loss: 0.015795841813087463\n",
      "- mean accuracy: 0.0546875\n",
      "- now 682\n",
      "- mean loss: 0.015846654772758484\n",
      "- mean accuracy: 0.0625\n",
      "- now 683\n",
      "- mean loss: 0.015811502933502197\n",
      "- mean accuracy: 0.03125\n",
      "- now 684\n",
      "- mean loss: 0.015681995078921318\n",
      "- mean accuracy: 0.0546875\n",
      "- now 685\n",
      "- mean loss: 0.015817273408174515\n",
      "- mean accuracy: 0.05078125\n",
      "- now 686\n",
      "- mean loss: 0.015834219753742218\n",
      "- mean accuracy: 0.0625\n",
      "- now 687\n",
      "- mean loss: 0.015125307254493237\n",
      "- mean accuracy: 0.0703125\n",
      "- now 688\n",
      "- mean loss: 0.015172668732702732\n",
      "- mean accuracy: 0.046875\n",
      "- now 689\n",
      "- mean loss: 0.015341741032898426\n",
      "- mean accuracy: 0.0625\n",
      "- now 690\n",
      "- mean loss: 0.015444907359778881\n",
      "- mean accuracy: 0.05078125\n",
      "- now 691\n",
      "- mean loss: 0.015143823809921741\n",
      "- mean accuracy: 0.0546875\n",
      "- now 692\n",
      "- mean loss: 0.015443401411175728\n",
      "- mean accuracy: 0.0390625\n",
      "- now 693\n",
      "- mean loss: 0.01533480267971754\n",
      "- mean accuracy: 0.0625\n",
      "- now 694\n",
      "- mean loss: 0.015242521651089191\n",
      "- mean accuracy: 0.0625\n",
      "- now 695\n",
      "- mean loss: 0.015755778178572655\n",
      "- mean accuracy: 0.03125\n",
      "- now 696\n",
      "- mean loss: 0.015366536565124989\n",
      "- mean accuracy: 0.04296875\n",
      "- now 697\n",
      "- mean loss: 0.01537137571722269\n",
      "- mean accuracy: 0.0546875\n",
      "- now 698\n",
      "- mean loss: 0.015391802415251732\n",
      "- mean accuracy: 0.0546875\n",
      "- now 699\n",
      "- mean loss: 0.015626640990376472\n",
      "- mean accuracy: 0.0546875\n",
      "- now 700\n",
      "- mean loss: 0.015459991991519928\n",
      "- mean accuracy: 0.046875\n",
      "- now 701\n",
      "- mean loss: 0.015345897525548935\n",
      "- mean accuracy: 0.046875\n",
      "- now 702\n",
      "- mean loss: 0.015341537073254585\n",
      "- mean accuracy: 0.0625\n",
      "- now 703\n",
      "- mean loss: 0.01510985940694809\n",
      "- mean accuracy: 0.07421875\n",
      "- now 704\n",
      "- mean loss: 0.015418092720210552\n",
      "- mean accuracy: 0.03515625\n",
      "- now 705\n",
      "- mean loss: 0.015281637199223042\n",
      "- mean accuracy: 0.04296875\n",
      "- now 706\n",
      "- mean loss: 0.01506016869097948\n",
      "- mean accuracy: 0.0390625\n",
      "- now 707\n",
      "- mean loss: 0.015157888643443584\n",
      "- mean accuracy: 0.0625\n",
      "- now 708\n",
      "- mean loss: 0.015038451179862022\n",
      "- mean accuracy: 0.04296875\n",
      "- now 709\n",
      "- mean loss: 0.015164503827691078\n",
      "- mean accuracy: 0.04296875\n",
      "- now 710\n",
      "- mean loss: 0.015113849192857742\n",
      "- mean accuracy: 0.0546875\n",
      "- now 711\n",
      "- mean loss: 0.015284101478755474\n",
      "- mean accuracy: 0.0625\n",
      "- now 712\n",
      "- mean loss: 0.015110085718333721\n",
      "- mean accuracy: 0.0625\n",
      "- now 713\n",
      "- mean loss: 0.015134232118725777\n",
      "- mean accuracy: 0.06640625\n",
      "- now 714\n",
      "- mean loss: 0.0153005076572299\n",
      "- mean accuracy: 0.0625\n",
      "- now 715\n",
      "- mean loss: 0.01480010338127613\n",
      "- mean accuracy: 0.04296875\n",
      "- now 716\n",
      "- mean loss: 0.014777382835745811\n",
      "- mean accuracy: 0.07421875\n",
      "- now 717\n",
      "- mean loss: 0.0151831628754735\n",
      "- mean accuracy: 0.0625\n",
      "- now 718\n",
      "- mean loss: 0.014934726990759373\n",
      "- mean accuracy: 0.06640625\n",
      "- now 719\n",
      "- mean loss: 0.015276006422936916\n",
      "- mean accuracy: 0.0546875\n",
      "- now 720\n",
      "- mean loss: 0.015128856524825096\n",
      "- mean accuracy: 0.05078125\n",
      "- now 721\n",
      "- mean loss: 0.015240331180393696\n",
      "- mean accuracy: 0.06640625\n",
      "- now 722\n",
      "- mean loss: 0.015485440380871296\n",
      "- mean accuracy: 0.0390625\n",
      "- now 723\n",
      "- mean loss: 0.01525389589369297\n",
      "- mean accuracy: 0.0625\n",
      "- now 724\n",
      "- mean loss: 0.015113581903278828\n",
      "- mean accuracy: 0.0859375\n",
      "- now 725\n",
      "- mean loss: 0.015130112878978252\n",
      "- mean accuracy: 0.06640625\n",
      "- now 726\n",
      "- mean loss: 0.015147462487220764\n",
      "- mean accuracy: 0.07421875\n",
      "- now 727\n",
      "- mean loss: 0.015421208925545216\n",
      "- mean accuracy: 0.0546875\n",
      "- now 728\n",
      "- mean loss: 0.015630410984158516\n",
      "- mean accuracy: 0.05859375\n",
      "- now 729\n",
      "- mean loss: 0.01541080791503191\n",
      "- mean accuracy: 0.0546875\n",
      "- now 730\n",
      "- mean loss: 0.015389770269393921\n",
      "- mean accuracy: 0.02734375\n",
      "- now 731\n",
      "- mean loss: 0.015640055760741234\n",
      "- mean accuracy: 0.0546875\n",
      "- now 732\n",
      "- mean loss: 0.015400645323097706\n",
      "- mean accuracy: 0.06640625\n",
      "- now 733\n",
      "- mean loss: 0.015478942543268204\n",
      "- mean accuracy: 0.0546875\n",
      "- now 734\n",
      "- mean loss: 0.015405183658003807\n",
      "- mean accuracy: 0.0703125\n",
      "- now 735\n",
      "- mean loss: 0.015133878216147423\n",
      "- mean accuracy: 0.05859375\n",
      "- now 736\n",
      "- mean loss: 0.014877794310450554\n",
      "- mean accuracy: 0.08984375\n",
      "- now 737\n",
      "- mean loss: 0.015024147927761078\n",
      "- mean accuracy: 0.06640625\n",
      "- now 738\n",
      "- mean loss: 0.014817074872553349\n",
      "- mean accuracy: 0.046875\n",
      "- now 739\n",
      "- mean loss: 0.01520599890500307\n",
      "- mean accuracy: 0.0546875\n",
      "- now 740\n",
      "- mean loss: 0.015146254561841488\n",
      "- mean accuracy: 0.0546875\n",
      "- now 741\n",
      "- mean loss: 0.015459854155778885\n",
      "- mean accuracy: 0.0703125\n",
      "- now 742\n",
      "- mean loss: 0.015619195066392422\n",
      "- mean accuracy: 0.05859375\n",
      "- now 743\n",
      "- mean loss: 0.015412361361086369\n",
      "- mean accuracy: 0.06640625\n",
      "- now 744\n",
      "- mean loss: 0.01507475133985281\n",
      "- mean accuracy: 0.0703125\n",
      "- now 745\n",
      "- mean loss: 0.015089438296854496\n",
      "- mean accuracy: 0.0703125\n",
      "- now 746\n",
      "- mean loss: 0.015285821631550789\n",
      "- mean accuracy: 0.0625\n",
      "- now 747\n",
      "- mean loss: 0.015415883623063564\n",
      "- mean accuracy: 0.04296875\n",
      "- now 748\n",
      "- mean loss: 0.015354050323367119\n",
      "- mean accuracy: 0.05078125\n",
      "- now 749\n",
      "- mean loss: 0.015489986166357994\n",
      "- mean accuracy: 0.0546875\n",
      "- now 750\n",
      "- mean loss: 0.015238677151501179\n",
      "- mean accuracy: 0.046875\n",
      "- now 751\n",
      "- mean loss: 0.01554691419005394\n",
      "- mean accuracy: 0.0546875\n",
      "- now 752\n",
      "- mean loss: 0.015413559041917324\n",
      "- mean accuracy: 0.05078125\n",
      "- now 753\n",
      "- mean loss: 0.015517402440309525\n",
      "- mean accuracy: 0.07421875\n",
      "- now 754\n",
      "- mean loss: 0.015292877331376076\n",
      "- mean accuracy: 0.0703125\n",
      "- now 755\n",
      "- mean loss: 0.015505882911384106\n",
      "- mean accuracy: 0.046875\n",
      "- now 756\n",
      "- mean loss: 0.01534197386354208\n",
      "- mean accuracy: 0.046875\n",
      "- now 757\n",
      "- mean loss: 0.015664389356970787\n",
      "- mean accuracy: 0.0703125\n",
      "- now 758\n",
      "- mean loss: 0.015137497335672379\n",
      "- mean accuracy: 0.08203125\n",
      "- now 759\n",
      "- mean loss: 0.015112445689737797\n",
      "- mean accuracy: 0.09765625\n",
      "- now 760\n",
      "- mean loss: 0.015196668915450573\n",
      "- mean accuracy: 0.0859375\n",
      "- now 761\n",
      "- mean loss: 0.015261354856193066\n",
      "- mean accuracy: 0.05859375\n",
      "- now 762\n",
      "- mean loss: 0.015360345132648945\n",
      "- mean accuracy: 0.06640625\n",
      "- now 763\n",
      "- mean loss: 0.015109934844076633\n",
      "- mean accuracy: 0.08203125\n",
      "- now 764\n",
      "- mean loss: 0.014828202314674854\n",
      "- mean accuracy: 0.08203125\n",
      "- now 765\n",
      "- mean loss: 0.015166684985160828\n",
      "- mean accuracy: 0.06640625\n",
      "- now 766\n",
      "- mean loss: 0.01527842041105032\n",
      "- mean accuracy: 0.046875\n",
      "- now 767\n",
      "- mean loss: 0.01479997206479311\n",
      "- mean accuracy: 0.07421875\n",
      "- now 768\n",
      "- mean loss: 0.014806807972490788\n",
      "- mean accuracy: 0.0703125\n",
      "- now 769\n",
      "- mean loss: 0.014954231679439545\n",
      "- mean accuracy: 0.0625\n",
      "- now 770\n",
      "- mean loss: 0.01489903125911951\n",
      "- mean accuracy: 0.05078125\n",
      "- now 771\n",
      "- mean loss: 0.015028686262667179\n",
      "- mean accuracy: 0.0703125\n",
      "- now 772\n",
      "- mean loss: 0.014774066396057606\n",
      "- mean accuracy: 0.06640625\n",
      "- now 773\n",
      "- mean loss: 0.015105446800589561\n",
      "- mean accuracy: 0.05078125\n",
      "- now 774\n",
      "- mean loss: 0.015179144218564034\n",
      "- mean accuracy: 0.04296875\n",
      "- now 775\n",
      "- mean loss: 0.01532205380499363\n",
      "- mean accuracy: 0.07421875\n",
      "- now 776\n",
      "- mean loss: 0.015162735246121883\n",
      "- mean accuracy: 0.0625\n",
      "- now 777\n",
      "- mean loss: 0.0154207032173872\n",
      "- mean accuracy: 0.05859375\n",
      "- now 778\n",
      "- mean loss: 0.01519371010363102\n",
      "- mean accuracy: 0.078125\n",
      "- now 779\n",
      "- mean loss: 0.015189766883850098\n",
      "- mean accuracy: 0.046875\n",
      "- now 780\n",
      "- mean loss: 0.015003223903477192\n",
      "- mean accuracy: 0.0625\n",
      "- now 781\n",
      "- mean loss: 0.015235049650073051\n",
      "- mean accuracy: 0.05859375\n",
      "- now 782\n",
      "- mean loss: 0.014840367250144482\n",
      "- mean accuracy: 0.05078125\n",
      "- now 783\n",
      "- mean loss: 0.015304087661206722\n",
      "- mean accuracy: 0.0703125\n",
      "- now 784\n",
      "- mean loss: 0.015241722576320171\n",
      "- mean accuracy: 0.06640625\n",
      "- now 785\n",
      "- mean loss: 0.015844915062189102\n",
      "- mean accuracy: 0.046875\n",
      "- now 786\n",
      "- mean loss: 0.015313648618757725\n",
      "- mean accuracy: 0.0703125\n",
      "- now 787\n",
      "- mean loss: 0.015725884586572647\n",
      "- mean accuracy: 0.078125\n",
      "- now 788\n",
      "- mean loss: 0.015555663034319878\n",
      "- mean accuracy: 0.0625\n",
      "- now 789\n",
      "- mean loss: 0.015218842774629593\n",
      "- mean accuracy: 0.0546875\n",
      "- now 790\n",
      "- mean loss: 0.015193214640021324\n",
      "- mean accuracy: 0.06640625\n",
      "- now 791\n",
      "- mean loss: 0.015412618406116962\n",
      "- mean accuracy: 0.07421875\n",
      "- now 792\n",
      "- mean loss: 0.015655573457479477\n",
      "- mean accuracy: 0.0625\n",
      "- now 793\n",
      "- mean loss: 0.015843989327549934\n",
      "- mean accuracy: 0.078125\n",
      "- now 794\n",
      "- mean loss: 0.015879828482866287\n",
      "- mean accuracy: 0.0546875\n",
      "- now 795\n",
      "- mean loss: 0.015510804019868374\n",
      "- mean accuracy: 0.06640625\n",
      "- now 796\n",
      "- mean loss: 0.015142609365284443\n",
      "- mean accuracy: 0.0546875\n",
      "- now 797\n",
      "- mean loss: 0.015283339656889439\n",
      "- mean accuracy: 0.046875\n",
      "- now 798\n",
      "- mean loss: 0.015756437554955482\n",
      "- mean accuracy: 0.0625\n",
      "- now 799\n",
      "- mean loss: 0.015426629222929478\n",
      "- mean accuracy: 0.078125\n",
      "- now 800\n",
      "- mean loss: 0.015218030661344528\n",
      "- mean accuracy: 0.05078125\n",
      "- now 801\n",
      "- mean loss: 0.01534894946962595\n",
      "- mean accuracy: 0.05859375\n",
      "- now 802\n",
      "- mean loss: 0.01526573020964861\n",
      "- mean accuracy: 0.05859375\n",
      "- now 803\n",
      "- mean loss: 0.015258027240633965\n",
      "- mean accuracy: 0.0546875\n",
      "- now 804\n",
      "- mean loss: 0.015248502604663372\n",
      "- mean accuracy: 0.0703125\n",
      "- now 805\n",
      "- mean loss: 0.015362650156021118\n",
      "- mean accuracy: 0.06640625\n",
      "- now 806\n",
      "- mean loss: 0.015092103742063046\n",
      "- mean accuracy: 0.08203125\n",
      "- now 807\n",
      "- mean loss: 0.015336315147578716\n",
      "- mean accuracy: 0.07421875\n",
      "- now 808\n",
      "- mean loss: 0.015306824818253517\n",
      "- mean accuracy: 0.05859375\n",
      "- now 809\n",
      "- mean loss: 0.015007393434643745\n",
      "- mean accuracy: 0.0859375\n",
      "- now 810\n",
      "- mean loss: 0.015148097649216652\n",
      "- mean accuracy: 0.0546875\n",
      "- now 811\n",
      "- mean loss: 0.015339504927396774\n",
      "- mean accuracy: 0.0546875\n",
      "- now 812\n",
      "- mean loss: 0.015114320442080498\n",
      "- mean accuracy: 0.0546875\n",
      "- now 813\n",
      "- mean loss: 0.015277255326509476\n",
      "- mean accuracy: 0.05859375\n",
      "- now 814\n",
      "- mean loss: 0.01534819696098566\n",
      "- mean accuracy: 0.03515625\n",
      "- now 815\n",
      "- mean loss: 0.015240772627294064\n",
      "- mean accuracy: 0.0859375\n",
      "- now 816\n",
      "- mean loss: 0.014954675920307636\n",
      "- mean accuracy: 0.05859375\n",
      "- now 817\n",
      "- mean loss: 0.015414600260555744\n",
      "- mean accuracy: 0.06640625\n",
      "- now 818\n",
      "- mean loss: 0.01518331840634346\n",
      "- mean accuracy: 0.05859375\n",
      "- now 819\n",
      "- mean loss: 0.015288139693439007\n",
      "- mean accuracy: 0.0390625\n",
      "- now 820\n",
      "- mean loss: 0.015235595405101776\n",
      "- mean accuracy: 0.07421875\n",
      "- now 821\n",
      "- mean loss: 0.015100677497684956\n",
      "- mean accuracy: 0.0625\n",
      "- now 822\n",
      "- mean loss: 0.015051773749291897\n",
      "- mean accuracy: 0.0703125\n",
      "- now 823\n",
      "- mean loss: 0.015249788761138916\n",
      "- mean accuracy: 0.0703125\n",
      "- now 824\n",
      "- mean loss: 0.015337742865085602\n",
      "- mean accuracy: 0.05078125\n",
      "- now 825\n",
      "- mean loss: 0.015541556291282177\n",
      "- mean accuracy: 0.0546875\n",
      "- now 826\n",
      "- mean loss: 0.01529712975025177\n",
      "- mean accuracy: 0.06640625\n",
      "- now 827\n",
      "- mean loss: 0.015371142886579037\n",
      "- mean accuracy: 0.0546875\n",
      "- now 828\n",
      "- mean loss: 0.01505393348634243\n",
      "- mean accuracy: 0.05078125\n",
      "- now 829\n",
      "- mean loss: 0.015235977247357368\n",
      "- mean accuracy: 0.0625\n",
      "- now 830\n",
      "- mean loss: 0.015032983385026455\n",
      "- mean accuracy: 0.05859375\n",
      "- now 831\n",
      "- mean loss: 0.015241053886711597\n",
      "- mean accuracy: 0.07421875\n",
      "- now 832\n",
      "- mean loss: 0.015098165720701218\n",
      "- mean accuracy: 0.0625\n",
      "- now 833\n",
      "- mean loss: 0.015676643699407578\n",
      "- mean accuracy: 0.04296875\n",
      "- now 834\n",
      "- mean loss: 0.015500695444643497\n",
      "- mean accuracy: 0.078125\n",
      "- now 835\n",
      "- mean loss: 0.015200435183942318\n",
      "- mean accuracy: 0.05859375\n",
      "- now 836\n",
      "- mean loss: 0.015170563012361526\n",
      "- mean accuracy: 0.046875\n",
      "- now 837\n",
      "- mean loss: 0.015429765917360783\n",
      "- mean accuracy: 0.04296875\n",
      "- now 838\n",
      "- mean loss: 0.015639597550034523\n",
      "- mean accuracy: 0.046875\n",
      "- now 839\n",
      "- mean loss: 0.015366720035672188\n",
      "- mean accuracy: 0.06640625\n",
      "- now 840\n",
      "- mean loss: 0.015210159122943878\n",
      "- mean accuracy: 0.0703125\n",
      "- now 841\n",
      "- mean loss: 0.01529712975025177\n",
      "- mean accuracy: 0.08203125\n",
      "- now 842\n",
      "- mean loss: 0.015440259128808975\n",
      "- mean accuracy: 0.046875\n",
      "- now 843\n",
      "- mean loss: 0.01523902639746666\n",
      "- mean accuracy: 0.0703125\n",
      "- now 844\n",
      "- mean loss: 0.015376489609479904\n",
      "- mean accuracy: 0.04296875\n",
      "- now 845\n",
      "- mean loss: 0.015588914975523949\n",
      "- mean accuracy: 0.04296875\n",
      "- now 846\n",
      "- mean loss: 0.015415177680552006\n",
      "- mean accuracy: 0.046875\n",
      "- now 847\n",
      "- mean loss: 0.015525107271969318\n",
      "- mean accuracy: 0.05859375\n",
      "- now 848\n",
      "- mean loss: 0.015277192927896976\n",
      "- mean accuracy: 0.05859375\n",
      "- now 849\n",
      "- mean loss: 0.015129252336919308\n",
      "- mean accuracy: 0.0625\n",
      "- now 850\n",
      "- mean loss: 0.015398172661662102\n",
      "- mean accuracy: 0.05859375\n",
      "- now 851\n",
      "- mean loss: 0.015415225178003311\n",
      "- mean accuracy: 0.05078125\n",
      "- now 852\n",
      "- mean loss: 0.01528728287667036\n",
      "- mean accuracy: 0.07421875\n",
      "- now 853\n",
      "- mean loss: 0.01523540262132883\n",
      "- mean accuracy: 0.05859375\n",
      "- now 854\n",
      "- mean loss: 0.015446995384991169\n",
      "- mean accuracy: 0.0703125\n",
      "- now 855\n",
      "- mean loss: 0.015629254281520844\n",
      "- mean accuracy: 0.05078125\n",
      "- now 856\n",
      "- mean loss: 0.015284082852303982\n",
      "- mean accuracy: 0.05859375\n",
      "- now 857\n",
      "- mean loss: 0.01511251088231802\n",
      "- mean accuracy: 0.0703125\n",
      "- now 858\n",
      "- mean loss: 0.015218288637697697\n",
      "- mean accuracy: 0.0703125\n",
      "- now 859\n",
      "- mean loss: 0.015066572465002537\n",
      "- mean accuracy: 0.0703125\n",
      "- now 860\n",
      "- mean loss: 0.015476016327738762\n",
      "- mean accuracy: 0.0546875\n",
      "- now 861\n",
      "- mean loss: 0.015488581731915474\n",
      "- mean accuracy: 0.0703125\n",
      "- now 862\n",
      "- mean loss: 0.015446382574737072\n",
      "- mean accuracy: 0.0546875\n",
      "- now 863\n",
      "- mean loss: 0.015291819348931313\n",
      "- mean accuracy: 0.06640625\n",
      "- now 864\n",
      "- mean loss: 0.015164310112595558\n",
      "- mean accuracy: 0.046875\n",
      "- now 865\n",
      "- mean loss: 0.015100848861038685\n",
      "- mean accuracy: 0.05859375\n",
      "- now 866\n",
      "- mean loss: 0.015464781783521175\n",
      "- mean accuracy: 0.07421875\n",
      "- now 867\n",
      "- mean loss: 0.015735086053609848\n",
      "- mean accuracy: 0.05859375\n",
      "- now 868\n",
      "- mean loss: 0.015380030497908592\n",
      "- mean accuracy: 0.0546875\n",
      "- now 869\n",
      "- mean loss: 0.015371165238320827\n",
      "- mean accuracy: 0.0390625\n",
      "- now 870\n",
      "- mean loss: 0.015467731282114983\n",
      "- mean accuracy: 0.05859375\n",
      "- now 871\n",
      "- mean loss: 0.015181190334260464\n",
      "- mean accuracy: 0.078125\n",
      "- now 872\n",
      "- mean loss: 0.015145491808652878\n",
      "- mean accuracy: 0.0546875\n",
      "- now 873\n",
      "- mean loss: 0.01528862863779068\n",
      "- mean accuracy: 0.05859375\n",
      "- now 874\n",
      "- mean loss: 0.015327456407248974\n",
      "- mean accuracy: 0.0546875\n",
      "- now 875\n",
      "- mean loss: 0.015348108485341072\n",
      "- mean accuracy: 0.05859375\n",
      "- now 876\n",
      "- mean loss: 0.01569957844913006\n",
      "- mean accuracy: 0.06640625\n",
      "- now 877\n",
      "- mean loss: 0.015512297861278057\n",
      "- mean accuracy: 0.06640625\n",
      "- now 878\n",
      "- mean loss: 0.01548071764409542\n",
      "- mean accuracy: 0.0625\n",
      "- now 879\n",
      "- mean loss: 0.015469929203391075\n",
      "- mean accuracy: 0.0546875\n",
      "- now 880\n",
      "- mean loss: 0.015028060413897038\n",
      "- mean accuracy: 0.08203125\n",
      "- now 881\n",
      "- mean loss: 0.015247078612446785\n",
      "- mean accuracy: 0.0703125\n",
      "- now 882\n",
      "- mean loss: 0.015252459794282913\n",
      "- mean accuracy: 0.0703125\n",
      "- now 883\n",
      "- mean loss: 0.0152867641299963\n",
      "- mean accuracy: 0.08203125\n",
      "- now 884\n",
      "- mean loss: 0.015237837098538876\n",
      "- mean accuracy: 0.0625\n",
      "- now 885\n",
      "- mean loss: 0.015213129110634327\n",
      "- mean accuracy: 0.04296875\n",
      "- now 886\n",
      "- mean loss: 0.015413232147693634\n",
      "- mean accuracy: 0.04296875\n",
      "- now 887\n",
      "- mean loss: 0.015176292508840561\n",
      "- mean accuracy: 0.0546875\n",
      "- now 888\n",
      "- mean loss: 0.015412000939249992\n",
      "- mean accuracy: 0.05078125\n",
      "- now 889\n",
      "- mean loss: 0.015212959609925747\n",
      "- mean accuracy: 0.05859375\n",
      "- now 890\n",
      "- mean loss: 0.015483206138014793\n",
      "- mean accuracy: 0.03515625\n",
      "- now 891\n",
      "- mean loss: 0.015346961095929146\n",
      "- mean accuracy: 0.04296875\n",
      "- now 892\n",
      "- mean loss: 0.015507146716117859\n",
      "- mean accuracy: 0.0546875\n",
      "- now 893\n",
      "- mean loss: 0.015392035245895386\n",
      "- mean accuracy: 0.05078125\n",
      "- now 894\n",
      "- mean loss: 0.015160657465457916\n",
      "- mean accuracy: 0.0859375\n",
      "- now 895\n",
      "- mean loss: 0.015590395778417587\n",
      "- mean accuracy: 0.08203125\n",
      "- now 896\n",
      "- mean loss: 0.015716155990958214\n",
      "- mean accuracy: 0.046875\n",
      "- now 897\n",
      "- mean loss: 0.015327130444347858\n",
      "- mean accuracy: 0.08203125\n",
      "- now 898\n",
      "- mean loss: 0.015583351254463196\n",
      "- mean accuracy: 0.0703125\n",
      "- now 899\n",
      "- mean loss: 0.015634741634130478\n",
      "- mean accuracy: 0.05859375\n",
      "- now 900\n",
      "- mean loss: 0.015913287177681923\n",
      "- mean accuracy: 0.0546875\n",
      "- now 901\n",
      "- mean loss: 0.015405540354549885\n",
      "- mean accuracy: 0.05859375\n",
      "- now 902\n",
      "- mean loss: 0.015654930844902992\n",
      "- mean accuracy: 0.04296875\n",
      "- now 903\n",
      "- mean loss: 0.015460089780390263\n",
      "- mean accuracy: 0.046875\n",
      "- now 904\n",
      "- mean loss: 0.015195654705166817\n",
      "- mean accuracy: 0.08984375\n",
      "- now 905\n",
      "- mean loss: 0.015309463255107403\n",
      "- mean accuracy: 0.07421875\n",
      "- now 906\n",
      "- mean loss: 0.015204307623207569\n",
      "- mean accuracy: 0.08984375\n",
      "- now 907\n",
      "- mean loss: 0.015293441712856293\n",
      "- mean accuracy: 0.0625\n",
      "- now 908\n",
      "- mean loss: 0.015460124239325523\n",
      "- mean accuracy: 0.08984375\n",
      "- now 909\n",
      "- mean loss: 0.015045033767819405\n",
      "- mean accuracy: 0.0546875\n",
      "- now 910\n",
      "- mean loss: 0.015492440201342106\n",
      "- mean accuracy: 0.0703125\n",
      "- now 911\n",
      "- mean loss: 0.015513376332819462\n",
      "- mean accuracy: 0.02734375\n",
      "- now 912\n",
      "- mean loss: 0.015233618207275867\n",
      "- mean accuracy: 0.078125\n",
      "- now 913\n",
      "- mean loss: 0.014970224350690842\n",
      "- mean accuracy: 0.0703125\n",
      "- now 914\n",
      "- mean loss: 0.015102671459317207\n",
      "- mean accuracy: 0.05859375\n",
      "- now 915\n",
      "- mean loss: 0.015251446515321732\n",
      "- mean accuracy: 0.046875\n",
      "- now 916\n",
      "- mean loss: 0.014955569058656693\n",
      "- mean accuracy: 0.05078125\n",
      "- now 917\n",
      "- mean loss: 0.014898465014994144\n",
      "- mean accuracy: 0.06640625\n",
      "- now 918\n",
      "- mean loss: 0.014999744482338428\n",
      "- mean accuracy: 0.0546875\n",
      "- now 919\n",
      "- mean loss: 0.014814144931733608\n",
      "- mean accuracy: 0.0703125\n",
      "- now 920\n",
      "- mean loss: 0.014849748462438583\n",
      "- mean accuracy: 0.04296875\n",
      "- now 921\n",
      "- mean loss: 0.014912700280547142\n",
      "- mean accuracy: 0.05859375\n",
      "- now 922\n",
      "- mean loss: 0.015101446770131588\n",
      "- mean accuracy: 0.046875\n",
      "- now 923\n",
      "- mean loss: 0.014830206520855427\n",
      "- mean accuracy: 0.05859375\n",
      "- now 924\n",
      "- mean loss: 0.01499407459050417\n",
      "- mean accuracy: 0.06640625\n",
      "- now 925\n",
      "- mean loss: 0.015050792135298252\n",
      "- mean accuracy: 0.0625\n",
      "- now 926\n",
      "- mean loss: 0.015179753303527832\n",
      "- mean accuracy: 0.0546875\n",
      "- now 927\n",
      "- mean loss: 0.014972303993999958\n",
      "- mean accuracy: 0.078125\n",
      "- now 928\n",
      "- mean loss: 0.015002996660768986\n",
      "- mean accuracy: 0.0625\n",
      "- now 929\n",
      "- mean loss: 0.015093805268406868\n",
      "- mean accuracy: 0.05078125\n",
      "- now 930\n",
      "- mean loss: 0.014464328996837139\n",
      "- mean accuracy: 0.06640625\n",
      "- now 931\n",
      "- mean loss: 0.014652838930487633\n",
      "- mean accuracy: 0.0625\n",
      "- now 932\n",
      "- mean loss: 0.01504388079047203\n",
      "- mean accuracy: 0.04296875\n",
      "- now 933\n",
      "- mean loss: 0.014981167390942574\n",
      "- mean accuracy: 0.04296875\n",
      "- now 934\n",
      "- mean loss: 0.01514841802418232\n",
      "- mean accuracy: 0.0546875\n",
      "- now 935\n",
      "- mean loss: 0.014870506711304188\n",
      "- mean accuracy: 0.05859375\n",
      "- now 936\n",
      "- mean loss: 0.014932556077837944\n",
      "- mean accuracy: 0.05859375\n",
      "- now 937\n",
      "- mean loss: 0.014553334563970566\n",
      "- mean accuracy: 0.0546875\n",
      "- now 938\n",
      "- mean loss: 0.014813306741416454\n",
      "- mean accuracy: 0.08203125\n",
      "- now 939\n",
      "- mean loss: 0.014485357329249382\n",
      "- mean accuracy: 0.08203125\n",
      "- now 940\n",
      "- mean loss: 0.014512818306684494\n",
      "- mean accuracy: 0.09765625\n",
      "- now 941\n",
      "- mean loss: 0.014994706027209759\n",
      "- mean accuracy: 0.05078125\n",
      "- now 942\n",
      "- mean loss: 0.0153668113052845\n",
      "- mean accuracy: 0.05859375\n",
      "- now 943\n",
      "- mean loss: 0.014806072227656841\n",
      "- mean accuracy: 0.046875\n",
      "- now 944\n",
      "- mean loss: 0.01489518117159605\n",
      "- mean accuracy: 0.078125\n",
      "- now 945\n",
      "- mean loss: 0.014691999182105064\n",
      "- mean accuracy: 0.09375\n",
      "- now 946\n",
      "- mean loss: 0.014515146613121033\n",
      "- mean accuracy: 0.08984375\n",
      "- now 947\n",
      "- mean loss: 0.01452669594436884\n",
      "- mean accuracy: 0.06640625\n",
      "- now 948\n",
      "- mean loss: 0.014748798683285713\n",
      "- mean accuracy: 0.0390625\n",
      "- now 949\n",
      "- mean loss: 0.01495339535176754\n",
      "- mean accuracy: 0.0703125\n",
      "- now 950\n",
      "- mean loss: 0.01442731823772192\n",
      "- mean accuracy: 0.0546875\n",
      "- now 951\n",
      "- mean loss: 0.015139788389205933\n",
      "- mean accuracy: 0.05859375\n",
      "- now 952\n",
      "- mean loss: 0.014520415104925632\n",
      "- mean accuracy: 0.0625\n",
      "- now 953\n",
      "- mean loss: 0.014863123185932636\n",
      "- mean accuracy: 0.078125\n",
      "- now 954\n",
      "- mean loss: 0.014939194545149803\n",
      "- mean accuracy: 0.07421875\n",
      "- now 955\n",
      "- mean loss: 0.014823232777416706\n",
      "- mean accuracy: 0.0625\n",
      "- now 956\n",
      "- mean loss: 0.01534849964082241\n",
      "- mean accuracy: 0.05859375\n",
      "- now 957\n",
      "- mean loss: 0.014863861724734306\n",
      "- mean accuracy: 0.05859375\n",
      "- now 958\n",
      "- mean loss: 0.014349140226840973\n",
      "- mean accuracy: 0.07421875\n",
      "- now 959\n",
      "- mean loss: 0.014321084134280682\n",
      "- mean accuracy: 0.078125\n",
      "- now 960\n",
      "- mean loss: 0.01476270891726017\n",
      "- mean accuracy: 0.0546875\n",
      "- now 961\n",
      "- mean loss: 0.014973328448832035\n",
      "- mean accuracy: 0.046875\n",
      "- now 962\n",
      "- mean loss: 0.01493699848651886\n",
      "- mean accuracy: 0.07421875\n",
      "- now 963\n",
      "- mean loss: 0.015004239976406097\n",
      "- mean accuracy: 0.0546875\n",
      "- now 964\n",
      "- mean loss: 0.014950370416045189\n",
      "- mean accuracy: 0.0703125\n",
      "- now 965\n",
      "- mean loss: 0.014751956798136234\n",
      "- mean accuracy: 0.0859375\n",
      "- now 966\n",
      "- mean loss: 0.014870352111756802\n",
      "- mean accuracy: 0.0625\n",
      "- now 967\n",
      "- mean loss: 0.015060669742524624\n",
      "- mean accuracy: 0.06640625\n",
      "- now 968\n",
      "- mean loss: 0.014914194121956825\n",
      "- mean accuracy: 0.0703125\n",
      "- now 969\n",
      "- mean loss: 0.014716117642819881\n",
      "- mean accuracy: 0.046875\n",
      "- now 970\n",
      "- mean loss: 0.014802784658968449\n",
      "- mean accuracy: 0.0625\n",
      "- now 971\n",
      "- mean loss: 0.014818134717643261\n",
      "- mean accuracy: 0.08203125\n",
      "- now 972\n",
      "- mean loss: 0.015111394226551056\n",
      "- mean accuracy: 0.05859375\n",
      "- now 973\n",
      "- mean loss: 0.015085829421877861\n",
      "- mean accuracy: 0.05078125\n",
      "- now 974\n",
      "- mean loss: 0.015086189843714237\n",
      "- mean accuracy: 0.06640625\n",
      "- now 975\n",
      "- mean loss: 0.015084289014339447\n",
      "- mean accuracy: 0.0703125\n",
      "- now 976\n",
      "- mean loss: 0.014681882224977016\n",
      "- mean accuracy: 0.05859375\n",
      "- now 977\n",
      "- mean loss: 0.015059491619467735\n",
      "- mean accuracy: 0.05078125\n",
      "- now 978\n",
      "- mean loss: 0.014900164678692818\n",
      "- mean accuracy: 0.05078125\n",
      "- now 979\n",
      "- mean loss: 0.014892502687871456\n",
      "- mean accuracy: 0.0390625\n",
      "- now 980\n",
      "- mean loss: 0.014736654236912727\n",
      "- mean accuracy: 0.046875\n",
      "- now 981\n",
      "- mean loss: 0.014899243600666523\n",
      "- mean accuracy: 0.04296875\n",
      "- now 982\n",
      "- mean loss: 0.01471091341227293\n",
      "- mean accuracy: 0.046875\n",
      "- now 983\n",
      "- mean loss: 0.014598391018807888\n",
      "- mean accuracy: 0.05078125\n",
      "- now 984\n",
      "- mean loss: 0.014795327559113503\n",
      "- mean accuracy: 0.07421875\n",
      "- now 985\n",
      "- mean loss: 0.014645228162407875\n",
      "- mean accuracy: 0.04296875\n",
      "- now 986\n",
      "- mean loss: 0.014639359898865223\n",
      "- mean accuracy: 0.03515625\n",
      "- now 987\n",
      "- mean loss: 0.014754349365830421\n",
      "- mean accuracy: 0.05078125\n",
      "- now 988\n",
      "- mean loss: 0.015050830319523811\n",
      "- mean accuracy: 0.0546875\n",
      "- now 989\n",
      "- mean loss: 0.015154010616242886\n",
      "- mean accuracy: 0.06640625\n",
      "- now 990\n",
      "- mean loss: 0.015174394473433495\n",
      "- mean accuracy: 0.05078125\n",
      "- now 991\n",
      "- mean loss: 0.014966826885938644\n",
      "- mean accuracy: 0.06640625\n",
      "- now 992\n",
      "- mean loss: 0.014948838390409946\n",
      "- mean accuracy: 0.06640625\n",
      "- now 993\n",
      "- mean loss: 0.015258864499628544\n",
      "- mean accuracy: 0.06640625\n",
      "- now 994\n",
      "- mean loss: 0.015000108629465103\n",
      "- mean accuracy: 0.07421875\n",
      "- now 995\n",
      "- mean loss: 0.01517520658671856\n",
      "- mean accuracy: 0.05859375\n",
      "- now 996\n",
      "- mean loss: 0.015081615187227726\n",
      "- mean accuracy: 0.0625\n",
      "- now 997\n",
      "- mean loss: 0.01497240923345089\n",
      "- mean accuracy: 0.0390625\n",
      "- now 998\n",
      "- mean loss: 0.01479335967451334\n",
      "- mean accuracy: 0.05859375\n",
      "- now 999\n",
      "- mean loss: 0.015053026378154755\n",
      "- mean accuracy: 0.046875\n",
      "1000time\n",
      "nice 0.09765625\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_e = x_batch[-1].to(device)\r\n",
    "t_e = t_batch[-1].to(device)\r\n",
    "y = mymodel(x)\r\n",
    "loss = F.cross_entropy(y_e, t_e)\r\n",
    "\r\n",
    "# 逆伝播\r\n",
    "\r\n",
    "loss.backward()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# ロスと精度を蓄積\r\n",
    "sum_loss += loss.item()\r\n",
    "sum_acc += (y.max(1)[1] == t).sum().item()\r\n",
    "\r\n",
    "#scheduler.step()\r\n",
    "\r\n",
    "mean_loss = sum_loss / len(x)\r\n",
    "mean_acc = sum_acc / len(x)\r\n",
    "list_loss_train.append(mean_loss)\r\n",
    "list_acc_train.append(mean_acc)\r\n",
    "plot_x.append(i)\r\n",
    "print(f\"- now {i}\")\r\n",
    "print(\"- mean loss:\", mean_loss)\r\n",
    "print(\"- mean accuracy:\", mean_acc) "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "90de0cb5340f2421d29f6927bfc29a54a0c5ffed6650aadb5a487ed8f622106d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
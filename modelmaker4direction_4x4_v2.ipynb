{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "import os\r\n",
    "from os.path import join\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "import random\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "n_epoch = 30000\r\n",
    "size_batch = 100\r\n",
    "\r\n",
    "def get_tensor(path):\r\n",
    "    tensor = torch.load(path)\r\n",
    "    tensor = np.array(tensor)\r\n",
    "    tensor = tensor.astype(np.float32)\r\n",
    "    return tensor\r\n",
    "\r\n",
    "def x_batch_maker(n):\r\n",
    "    n  = list(map(get_tensor,n))\r\n",
    "    return torch.tensor(n)\r\n",
    "\r\n",
    "def get_class(n):\r\n",
    "    c = str(n).split('/')[-2]\r\n",
    "    c = int(c.split(\"_\")[-1])\r\n",
    "    return c\r\n",
    "\r\n",
    "def t_batch_maker(n):\r\n",
    "    n = list(map(get_class,n))\r\n",
    "    return torch.tensor(n)\r\n",
    "\r\n",
    "test_list = [[f\"E:/procon/data/4x4_LearnDirection_v7/{k}/{a*size_batch + j}.pt\" for j in range(size_batch) for k in range(4)] for a in range(n_epoch)]\r\n",
    "x_batch =  map(x_batch_maker,test_list)\r\n",
    "t_batch =  map(t_batch_maker,test_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class directionModel(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        # self.fc1 = nn.Linear(4*4*4,64)# Input Layer to Intermediate modules\r\n",
    "        # self.fc2 = nn.Linear(64,64) #Intermediate modules to Output Layer\r\n",
    "        # self.fca = nn.Linear(64,64)\r\n",
    "        # self.fc3 = nn.Linear(64,32) #Intermediate modules to Output Layer\r\n",
    "        # self.fc4 = nn.Linear(32,32) #Intermediate modules to Output Layer\r\n",
    "        # self.fcb = nn.Linear(32,32)\r\n",
    "        # self.fc5 = nn.Linear(32,16) #Intermediate modules to Output Layer\r\n",
    "        # self.fc6 = nn.Linear(16,16)\r\n",
    "        # self.fcc = nn.Linear(16,16)\r\n",
    "        # self.fc7 = nn.Linear(16,8)\r\n",
    "        # self.fc8 = nn.Linear(8,8)\r\n",
    "        # self.fc9 = nn.Linear(8,4)  \r\n",
    "        self.c0 = nn.Conv2d(in_channels=4,    # 入力は3チャネル\r\n",
    "                            out_channels=16,  # 出力は16チャネル\r\n",
    "                            kernel_size=3,    # カーネルサイズは3*3\r\n",
    "                            stride=1,         # 1pix飛ばしでカーネルを移動\r\n",
    "                            padding=1)        # 画像の外側1pixを埋める\r\n",
    "\r\n",
    "        self.c1 = nn.Conv2d(in_channels=16,   # 入力は16チャネル\r\n",
    "                            out_channels=32,  # 出力は32チャネル\r\n",
    "                            kernel_size=3,    # カーネルサイズは3*3\r\n",
    "                            stride=1,         # 1pix飛ばしでカーネルを移動\r\n",
    "                            padding=1)        # 画像の外側1pixを埋める\r\n",
    "\r\n",
    "        self.c2 = nn.Conv2d(in_channels=32,   # 入力は32チャネル\r\n",
    "                            out_channels=64,  # 出力は64チャネル\r\n",
    "                            kernel_size=3,    # カーネルサイズは3*3\r\n",
    "                            stride=1,         # 1pix飛ばしでカーネルを移動\r\n",
    "                            padding=1)        # 画像の外側1pixを埋める       \r\n",
    "\r\n",
    "        self.c3 = nn.Conv2d(in_channels=64,   # 入力は32チャネル\r\n",
    "                            out_channels=128,  # 出力は64チャネル\r\n",
    "                            kernel_size=3,    # カーネルサイズは3*3\r\n",
    "                            stride=1,         # 1pix飛ばしでカーネルを移動\r\n",
    "                            padding=1)    \r\n",
    "        \r\n",
    "        self.c4 = nn.Conv2d(in_channels=128,   # 入力は32チャネル\r\n",
    "                            out_channels=256,  # 出力は64チャネル\r\n",
    "                            kernel_size=3,    # カーネルサイズは3*3\r\n",
    "                            stride=1,         # 1pix飛ばしでカーネルを移動\r\n",
    "                            padding=1) \r\n",
    "\r\n",
    "        self.bn0 = nn.BatchNorm2d(num_features=16)   # c0用のバッチ正則化\r\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=32)   # c1用のバッチ正則化\r\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64)   # c2用のバッチ正則化\r\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=128)\r\n",
    "        self.bn4 = nn.BatchNorm2d(num_features=256)\r\n",
    "        self.fc = nn.Linear(256 * 4 * 4, 4) \r\n",
    "\r\n",
    "    def forward(self, x):#順伝播 Forward propagation\r\n",
    "        # x = x.view(-1,4*4*4)\r\n",
    "        # x = self.fc1(x)\r\n",
    "        # x = self.fc2(x)\r\n",
    "        # x = self.fca(x)\r\n",
    "        # x = self.fc3(x)\r\n",
    "        # x = self.fc4(x)\r\n",
    "        # x = self.fcb(x)\r\n",
    "        # x = self.fc5(x)\r\n",
    "        # x = self.fc6(x)\r\n",
    "        # x = self.fcc(x)\r\n",
    "        # x = self.fc7(x)\r\n",
    "        # x = self.fc8(x)\r\n",
    "        # y = self.fc9(x)\r\n",
    "        h = F.relu(self.bn0(self.c0(x)))\r\n",
    "        h = F.relu(self.bn1(self.c1(h)))\r\n",
    "        h = F.relu(self.bn2(self.c2(h)))  \r\n",
    "        h = F.relu(self.bn3(self.c3(h))) \r\n",
    "        h = F.relu(self.bn4(self.c4(h))) \r\n",
    "        h = h.view(-1, 256 * 4 * 4)\r\n",
    "        y = self.fc(h)     # 全結合層\r\n",
    "        return y\r\n",
    "\r\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "mymodel = directionModel().to(device)\r\n",
    "opt = optim.Adagrad(mymodel.parameters(), lr=0.07)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_x = []\r\n",
    "# ロスと精度を保存するリスト（訓練用・テスト用）\r\n",
    "list_loss_train = []\r\n",
    "list_loss_test = []\r\n",
    "list_acc_train = []\r\n",
    "list_acc_test = []\r\n",
    "list_acc_all  =[]\r\n",
    "plot_xx = []\r\n",
    "\r\n",
    "temp_accs = []\r\n",
    "temp_max = 0\r\n",
    "temp_model = mymodel\r\n",
    "i = 0\r\n",
    "nice = 0\r\n",
    "kk = 0\r\n",
    "stay = [0.25]\r\n",
    "print(len(stay))\r\n",
    "mymodel.train()\r\n",
    "while i < n_epoch:\r\n",
    "    \r\n",
    "    sum_loss = 0.\r\n",
    "    sum_acc = 0.\r\n",
    "    test_acc = 0.\r\n",
    "    opt.zero_grad()\r\n",
    "    \r\n",
    "    x = next(x_batch).to(device)\r\n",
    "    t = next(t_batch).to(device)\r\n",
    "    y = mymodel(x)\r\n",
    "    loss = F.cross_entropy(y, t)\r\n",
    "\r\n",
    "    # 逆伝播\r\n",
    "    \r\n",
    "    loss.backward()\r\n",
    "\r\n",
    "    \r\n",
    "\r\n",
    "    # ロスと精度を蓄積\r\n",
    "    sum_loss += loss.item()\r\n",
    "    sum_acc += (y.max(1)[1] == t).sum().item()\r\n",
    "\r\n",
    "    # パラメータ更新\r\n",
    "    \r\n",
    "    #scheduler.step()\r\n",
    "\r\n",
    "    batch_loss = sum_loss / len(x)\r\n",
    "    batch_acc = sum_acc / len(x)\r\n",
    "    list_loss_train.append(batch_loss)\r\n",
    "\r\n",
    "    \r\n",
    "\r\n",
    "    print(f\"- now {i}\")\r\n",
    "    #print(\"- mean loss:\", mean_loss)\r\n",
    "    print(\"- batch accuracy:\", batch_acc) \r\n",
    "    print(\"- max accuracy:\", temp_max)\r\n",
    "    temp_accs.append(batch_acc)\r\n",
    "    \r\n",
    "    if i%1500==0 and i != 0:\r\n",
    "        ave = sum(temp_accs)/1500\r\n",
    "        temp_accs.clear()\r\n",
    "        list_acc_train.append(ave)\r\n",
    "        plot_x.append(i)\r\n",
    "        # if ave < 0.2:\r\n",
    "        #     mymodel = temp_model\r\n",
    "        #     i = i -100 \r\n",
    "        \r\n",
    "\r\n",
    "    # if batch_acc > 0.8:\r\n",
    "    #     i += 1\r\n",
    "    # elif batch_acc > 0.85 or kk > 100:\r\n",
    "    #     i+= 1\r\n",
    "    #     kk = 0\r\n",
    "    # else:\r\n",
    "    #     kk += 1\r\n",
    "    opt.step()\r\n",
    "    i += 1\r\n",
    "    \r\n",
    "    \r\n",
    "    \r\n",
    "      \r\n",
    "\r\n",
    "print(\"fin v5 both steped\")\r\n",
    "\r\n",
    "#print(list_acc_train)\r\n",
    "print(f\"max acc {max(list_acc_train)}\")\r\n",
    "print(f\"-mean acc {sum(list_acc_train)/len(list_acc_train)}\")\r\n",
    "plt.plot(plot_x,list_acc_train)\r\n",
    "print(nice)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ev_epoch = 100\r\n",
    "size_batch = 10\r\n",
    "\r\n",
    "test_list = [[f\"E:/procon/data/4x4_LearnDirection_v7/{k}/{size_batch*n_epoch+a*size_batch + j}.pt\" for j in range(size_batch) for k in range(4)] for a in range(ev_epoch)]\r\n",
    "ex_batch =  map(x_batch_maker,test_list)\r\n",
    "et_batch =  map(t_batch_maker,test_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "eve_accs = []\r\n",
    "eve_x =[]\r\n",
    "\r\n",
    "for i in range(ev_epoch):\r\n",
    "    sum_acc = 0.\r\n",
    "\r\n",
    "    x_e = next(ex_batch).to(device)\r\n",
    "    t_e = next(et_batch).to(device)\r\n",
    "    mymodel.eval()\r\n",
    "    y = mymodel(x_e)\r\n",
    "    sum_acc += (y.max(1)[1] == t).sum().item()\r\n",
    "    mean_acc = sum_acc / len(x)\r\n",
    "    eve_accs.append(mean_acc)\r\n",
    "    eve_x.append(i)\r\n",
    "    print(f\"- now {i}\")\r\n",
    "    print(\"- batch accuracy:\", mean_acc) \r\n",
    "\r\n",
    "print(f\"-mean acc :{sum(eve_accs)/len(eve_accs)}\")\r\n",
    "plt.plot(eve_x,eve_accs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix\r\n",
    "import seaborn  as sns\r\n",
    "ys = []\r\n",
    "ts = []\r\n",
    "for i in range(ev_epoch):\r\n",
    "    ex = next(ex_batch).to(device)\r\n",
    "    et = next(et_batch).to(device)\r\n",
    "\r\n",
    "    y = mymodel(ex)\r\n",
    "    y = torch.argmax(y, dim=1) # 確率の最大のインデックスを取得\r\n",
    "    ys.append(y.cpu()) \r\n",
    "    ts.append(et.cpu())\r\n",
    "\r\n",
    "ys = torch.cat(ys, dim=0)\r\n",
    "ts = torch.cat(ts, dim=0)\r\n",
    "\r\n",
    "# confusion matrixを表示するための関数\r\n",
    "\r\n",
    "def plot_confusion_matrix(cm,\r\n",
    "                          classes,\r\n",
    "                          normalize=False,\r\n",
    "                          title='Confusion matrix',\r\n",
    "                          cmap=plt.cm.Blues):\r\n",
    "    \"\"\"\r\n",
    "    This function prints and plots the confusion matrix.\r\n",
    "    Normalization can be applied by setting `normalize=True`.\r\n",
    "    \"\"\"\r\n",
    "    if normalize:\r\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n",
    "        print(\"Normalized confusion matrix\")\r\n",
    "    else:\r\n",
    "        print('Confusion matrix, without normalization')\r\n",
    "\r\n",
    "    print(cm)\r\n",
    "\r\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
    "    plt.title(title)\r\n",
    "    plt.colorbar()\r\n",
    "    tick_marks = np.arange(len(classes))\r\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\r\n",
    "    plt.yticks(tick_marks, classes)\r\n",
    "\r\n",
    "    fmt = '.2f' if normalize else 'd'\r\n",
    "    thresh = cm.max() / 2.\r\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\r\n",
    "                 horizontalalignment=\"center\",\r\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
    "\r\n",
    "    plt.tight_layout()\r\n",
    "    plt.ylabel('True label')\r\n",
    "    plt.xlabel('Predicted label')\r\n",
    "\r\n",
    "confmat = confusion_matrix(ys, ts)\r\n",
    "confmat\r\n",
    "\r\n",
    "#array([[879,  91],\r\n",
    "#       [ 88, 950]])\r\n",
    "\r\n",
    "classes = ['0','1','2','3','4']\r\n",
    "\r\n",
    "plt.figure(figsize=(6, 6))\r\n",
    "plot_confusion_matrix(confmat, classes=classes, normalize=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "90de0cb5340f2421d29f6927bfc29a54a0c5ffed6650aadb5a487ed8f622106d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}